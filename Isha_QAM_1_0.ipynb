{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Manus Impulse and Gaussian Decision Tree - QAM-16 Constellation Classifier\n",
        "\n",
        "This program implements a decision tree classifier for QAM-16 constellation\n",
        "classification with multiclass output from 0 to 15. It handles complex number\n",
        "inputs with both Gaussian and impulse noise by extracting appropriate features."
      ],
      "metadata": {
        "id": "Ua3dKNgZEKvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import tree\n",
        "import seaborn as sns\n",
        "from typing import Tuple, Dict, Any"
      ],
      "metadata": {
        "id": "INtK5pKqEM2X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "fShnzYLcEpSx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates the 16 complex numbers that represent the ideal QAM-16 constellation points. These points are arranged in a 4x4 grid in the complex plane.\n",
        "Normalizes the energy of the constellation points.\n",
        "Returns the array of constellation points and a dictionary that maps each complex constellation point to its corresponding integer label (0 to 15)"
      ],
      "metadata": {
        "id": "kkFHMPnpJI7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Generation ---\n",
        "def generate_qam16_constellation() -> Tuple[np.ndarray, Dict[complex, int]]:\n",
        "    \"\"\"Generates the 16-QAM constellation and its mapping.\"\"\"\n",
        "    constellation_points = np.array([\n",
        "        -3-3j, -3-1j, -3+1j, -3+3j,\n",
        "        -1-3j, -1-1j, -1+1j, -1+3j,\n",
        "        1-3j,  1-1j,  1+1j,  1+3j,\n",
        "        3-3j,  3-1j,  3+1j,  3+3j\n",
        "    ]) / np.sqrt(10)  # Normalize energy\n",
        "    mapping = {complex(point): i for i, point in enumerate(constellation_points)}\n",
        "    return constellation_points, mapping\n",
        "\n",
        "# Example usage (moved outside the function definition):\n",
        "constellation, mapping = generate_qam16_constellation()\n",
        "print(\"Constellation Points:\")\n",
        "print(constellation)\n",
        "print(\"\\nMapping (Complex Point -> Index):\")\n",
        "print(mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFNevhiPEs7b",
        "outputId": "14eee58a-ab54-41b0-b227-365dbbbe9b5e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constellation Points:\n",
            "[-0.9486833 -0.9486833j  -0.9486833 -0.31622777j -0.9486833 +0.31622777j\n",
            " -0.9486833 +0.9486833j  -0.31622777-0.9486833j  -0.31622777-0.31622777j\n",
            " -0.31622777+0.31622777j -0.31622777+0.9486833j   0.31622777-0.9486833j\n",
            "  0.31622777-0.31622777j  0.31622777+0.31622777j  0.31622777+0.9486833j\n",
            "  0.9486833 -0.9486833j   0.9486833 -0.31622777j  0.9486833 +0.31622777j\n",
            "  0.9486833 +0.9486833j ]\n",
            "\n",
            "Mapping (Complex Point -> Index):\n",
            "{(-0.9486832980505138-0.9486832980505138j): 0, (-0.9486832980505138-0.31622776601683794j): 1, (-0.9486832980505138+0.31622776601683794j): 2, (-0.9486832980505138+0.9486832980505138j): 3, (-0.31622776601683794-0.9486832980505138j): 4, (-0.31622776601683794-0.31622776601683794j): 5, (-0.31622776601683794+0.31622776601683794j): 6, (-0.31622776601683794+0.9486832980505138j): 7, (0.31622776601683794-0.9486832980505138j): 8, (0.31622776601683794-0.31622776601683794j): 9, (0.31622776601683794+0.31622776601683794j): 10, (0.31622776601683794+0.9486832980505138j): 11, (0.9486832980505138-0.9486832980505138j): 12, (0.9486832980505138-0.31622776601683794j): 13, (0.9486832980505138+0.31622776601683794j): 14, (0.9486832980505138+0.9486832980505138j): 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add_gaussian_noise(): Adds complex Gaussian noise to a given signal. The amount of noise is controlled by the Signal-to-Noise Ratio (SNR) in dB."
      ],
      "metadata": {
        "id": "ZgFXDab4JSai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_gaussian_noise(signal: np.ndarray, snr_db: float) -> np.ndarray:\n",
        "    \"\"\"Adds Gaussian noise to a complex signal based on SNR.\"\"\"\n",
        "    signal_power = np.mean(np.abs(signal)**2)\n",
        "    snr_linear = 10**(snr_db/10)\n",
        "    noise_power = signal_power / snr_linear\n",
        "    noise_std = np.sqrt(noise_power/2)\n",
        "    noise = noise_std * (np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
        "    return signal + noise\n",
        "\n",
        "# Example usage:\n",
        "# Create a sample signal (replace with your actual signal)\n",
        "sample_signal = np.array([1+1j, 2-1j, -0.5+0.8j, -1-2j])\n",
        "snr_db_value = 20  # Example SNR in dB\n",
        "\n",
        "noisy_signal = add_gaussian_noise(sample_signal, snr_db_value)\n",
        "print(\"Original Signal:\")\n",
        "print(sample_signal)\n",
        "print(\"\\nNoisy Signal (with SNR = {} dB):\".format(snr_db_value))\n",
        "print(noisy_signal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exC33fWCE2D0",
        "outputId": "bed14310-7d05-49ba-df82-c851f8b5f985"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Signal:\n",
            "[ 1. +1.j   2. -1.j  -0.5+0.8j -1. -2.j ]\n",
            "\n",
            "Noisy Signal (with SNR = 20 dB):\n",
            "[ 1.06305042+0.97027774j  1.98244942-1.02972018j -0.41778564+1.00045741j\n",
            " -0.80667417-1.90258566j]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add_impulse_noise(): Adds impulse noise to a signal. Impulse noise introduces sudden, high-amplitude disturbances with a specified probability and amplitude."
      ],
      "metadata": {
        "id": "rYJ-F_jQJhPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_impulse_noise(signal: np.ndarray, impulse_prob: float = 0.05, impulse_amplitude: float = 5.0) -> np.ndarray:\n",
        "\n",
        "    # Create a mask for impulse locations\n",
        "    impulse_mask = np.random.random(signal.shape) < impulse_prob\n",
        "\n",
        "    # Generate complex impulses with random phases\n",
        "    impulse_phases = np.random.uniform(0, 2*np.pi, size=np.sum(impulse_mask))\n",
        "    impulses = impulse_amplitude * np.exp(1j * impulse_phases)\n",
        "\n",
        "    # Create noisy signal (copy to avoid modifying original)\n",
        "    noisy_signal = signal.copy()\n",
        "\n",
        "    # Apply impulses to the masked positions\n",
        "    noisy_signal.flat[np.flatnonzero(impulse_mask)] = impulses\n",
        "\n",
        "    return noisy_signal\n",
        "\n",
        "# Example usage:\n",
        "# Create a sample complex signal\n",
        "sample_signal = np.array([1+0j, 0.5+0.5j, -1-1j, 0-2j, 2+1.5j])\n",
        "\n",
        "# Add impulse noise\n",
        "noisy_signal = add_impulse_noise(sample_signal, impulse_prob=0.1, impulse_amplitude=3.0)\n",
        "\n",
        "print(\"Original Signal:\")\n",
        "print(sample_signal)\n",
        "print(\"\\nNoisy Signal with Impulse Noise:\")\n",
        "print(noisy_signal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4d0O_dKNyNK",
        "outputId": "92ea4c11-5fa9-4f58-fffe-04f3f8a39527"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Signal:\n",
            "[ 1. +0.j   0.5+0.5j -1. -1.j   0. -2.j   2. +1.5j]\n",
            "\n",
            "Noisy Signal with Impulse Noise:\n",
            "[ 1.21898415+2.7411818j  0.5       +0.5j       -1.        -1.j\n",
            "  0.        -2.j         2.        +1.5j      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add_impulse_noise(): Adds impulse noise to a signal. Impulse noise introduces sudden, high-amplitude disturbances with a specified probability and amplitude."
      ],
      "metadata": {
        "id": "axowzG6YJoex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_combined_noise(signal: np.ndarray, snr_db: float, impulse_prob: float, impulse_amplitude: float) -> np.ndarray:\n",
        "    \"\"\"Adds both Gaussian and impulse noise to a complex signal.\"\"\"\n",
        "    noisy_signal = add_gaussian_noise(signal, snr_db)\n",
        "    noisy_signal = add_impulse_noise(noisy_signal, impulse_prob, impulse_amplitude)\n",
        "    return noisy_signal\n",
        "\n",
        "print(\"add_combined_noise:\")\n",
        "print(noisy_signal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hayfcmP1GPhW",
        "outputId": "ca4332cd-4523-4918-d782-7918c72b540a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "add_combined_noise:\n",
            "[ 1.21898415+2.7411818j  0.5       +0.5j       -1.        -1.j\n",
            "  0.        -2.j         2.        +1.5j      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate_dataset():\n",
        "\n",
        "Creates a dataset of QAM-16 symbols with different types of noise.\n",
        "num_samples: Specifies the total number of data points to generate.\n",
        "noise_types: A dictionary that configures which noise types to generate and their parameters (SNR range for Gaussian, probability and amplitude range for impulse). If None, it uses default configurations for \"Clean\", \"Gaussian\", \"Impulse\", and \"Combined\" noise.\n",
        "For each specified noise type:\n",
        "Generates clean QAM-16 symbols by randomly selecting from the constellation.\n",
        "Adds the corresponding noise based on the configuration.\n",
        "Extracts features from the noisy complex signals using the extract_features() function.\n",
        "Returns a dictionary datasets where keys are noise types and values are dictionaries containing the noisy complex signals (complex) and the extracted features (features), along with the original labels y."
      ],
      "metadata": {
        "id": "nJCImgwpJwwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(num_samples: int = 10000, noise_types: Dict[str, Dict[str, Any]] = None) -> Tuple[Dict[str, Dict[str, np.ndarray]], np.ndarray]:\n",
        "    \"\"\"Generates a QAM-16 dataset with configurable noise types.\"\"\"\n",
        "    if noise_types is None:\n",
        "        noise_types = {\n",
        "            \"Clean\": {\"gaussian\": False, \"impulse\": False},\n",
        "            \"Gaussian\": {\"gaussian\": True, \"impulse\": False, \"snr_db_range\": (10, 30)},\n",
        "            \"Impulse\": {\"gaussian\": False, \"impulse\": True, \"impulse_prob_range\": (0.01, 0.1), \"impulse_amplitude_range\": (2.0, 5.0)},\n",
        "            \"Combined\": {\"gaussian\": True, \"impulse\": True, \"snr_db_range\": (10, 30), \"impulse_prob_range\": (0.01, 0.1), \"impulse_amplitude_range\": (2.0, 5.0)}\n",
        "        }\n",
        "\n",
        "    constellation, _ = generate_qam16_constellation()\n",
        "    indices = np.random.randint(0, 16, size=num_samples)\n",
        "    labels = indices.copy()\n",
        "    clean_signals = constellation[indices]\n",
        "    datasets = {}\n",
        "    for noise_name, config in noise_types.items():\n",
        "        noisy_signals = clean_signals.copy()\n",
        "\n",
        "        if noise_name == \"Gaussian\" and config.get(\"gaussian\"):\n",
        "            snr_range = config.get(\"snr_db_range\", (20, 20))\n",
        "            snr_values = np.random.uniform(snr_range[0], snr_range[1], size=num_samples)\n",
        "            noisy_signals = np.array([add_gaussian_noise(np.array([s]), snr)[0] for s, snr in zip(clean_signals, snr_values)])\n",
        "\n",
        "        elif noise_name == \"Impulse\" and config.get(\"impulse\"):\n",
        "            prob_range = config.get(\"impulse_prob_range\", (0.05, 0.05))\n",
        "            amp_range = config.get(\"impulse_amplitude_range\", (3.0, 3.0))\n",
        "            probs = np.random.uniform(prob_range[0], prob_range[1], size=num_samples)\n",
        "            amps = np.random.uniform(amp_range[0], amp_range[1], size=num_samples)\n",
        "            noisy_signals = np.array([add_impulse_noise(np.array([s]), p, a)[0] for s, p, a in zip(clean_signals, probs, amps)])\n",
        "\n",
        "        elif noise_name == \"Combined\" and config.get(\"gaussian\") and config.get(\"impulse\"):\n",
        "            snr_range = config.get(\"snr_db_range\", (20, 20))\n",
        "            prob_range = config.get(\"impulse_prob_range\", (0.05, 0.05))\n",
        "            amp_range = config.get(\"impulse_amplitude_range\", (3.0, 3.0))\n",
        "            snr_values = np.random.uniform(snr_range[0], snr_range[1], size=num_samples)\n",
        "            probs = np.random.uniform(prob_range[0], prob_range[1], size=num_samples)\n",
        "            amps = np.random.uniform(amp_range[0], amp_range[1], size=num_samples)\n",
        "            noisy_signals = np.array([add_combined_noise(np.array([s]), snr, p, a)[0] for s, snr, p, a in zip(clean_signals, snr_values, probs, amps)])\n",
        "\n",
        "        features = extract_features(noisy_signals)\n",
        "        datasets[noise_name] = {\"complex\": noisy_signals, \"features\": features}\n",
        "\n",
        "    return datasets, labels\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    datasets, labels = generate_dataset(num_samples=5000)\n",
        "\n",
        "    print(\"generate_dataset:\")\n",
        "    print(\"Datasets:\")\n",
        "    for noise_type, data in datasets.items():\n",
        "        print(f\"  {noise_type}:\")\n",
        "        print(f\"    Complex Signals Shape: {data['complex'].shape}\")\n",
        "        print(f\"    Features Shape: {data['features'].shape}\")\n",
        "\n",
        "    print(\"\\nLabels:\")\n",
        "    print(f\"  Shape: {labels.shape}\")\n",
        "    print(f\"  First 10 labels: {labels[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ILrfDT8GUM_",
        "outputId": "8c7259c0-9429-4a7c-8ac1-5994022bc4d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate_dataset:\n",
            "Datasets:\n",
            "  Clean:\n",
            "    Complex Signals Shape: (5000,)\n",
            "    Features Shape: (5000, 2)\n",
            "  Gaussian:\n",
            "    Complex Signals Shape: (5000,)\n",
            "    Features Shape: (5000, 2)\n",
            "  Impulse:\n",
            "    Complex Signals Shape: (5000,)\n",
            "    Features Shape: (5000, 2)\n",
            "  Combined:\n",
            "    Complex Signals Shape: (5000,)\n",
            "    Features Shape: (5000, 2)\n",
            "\n",
            "Labels:\n",
            "  Shape: (5000,)\n",
            "  First 10 labels: [11  9  5 12 11  8  0 10 10 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract_features():\n",
        "\n",
        "Takes an array of complex numbers as input.\n",
        "Extracts several features from each complex number that are intended to be useful for classification and robust to noise:\n",
        "Real part\n",
        "Imaginary part\n",
        "Magnitude\n",
        "Phase (angle)\n",
        "Logarithm of the magnitude (can help with robustness to large impulse noise values)\n",
        "Rank of the real part within the batch (normalized to 0-1) - robust to outliers.\n",
        "Rank of the imaginary part within the batch (normalized to 0-1) - robust to outliers.\n",
        "Quadrant of the complex number in the complex plane.\n",
        "Returns a 2D NumPy array where each row represents a sample and each column represents a feature."
      ],
      "metadata": {
        "id": "cTwX6LHDKAVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Feature Extraction ---\n",
        "def extract_features(X_complex: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Extracts features from complex inputs robust to noise.\"\"\"\n",
        "    real_part = X_complex.real\n",
        "    imag_part = X_complex.imag\n",
        "    magnitude = np.abs(X_complex)\n",
        "    phase = np.angle(X_complex)\n",
        "    log_magnitude = np.log1p(magnitude)\n",
        "\n",
        "    real_rank = np.argsort(np.argsort(real_part)) / len(real_part)\n",
        "    imag_rank = np.argsort(np.argsort(imag_part)) / len(imag_part)\n",
        "\n",
        "    quadrant = np.zeros_like(real_part, dtype=int)\n",
        "    quadrant[(real_part >= 0) & (imag_part >= 0)] = 0\n",
        "    quadrant[(real_part < 0) & (imag_part >= 0)] = 1\n",
        "    quadrant[(real_part < 0) & (imag_part < 0)] = 2\n",
        "    quadrant[(real_part >= 0) & (imag_part < 0)] = 3\n",
        "\n",
        "    return np.column_stack((real_part, imag_part, magnitude, phase,\n",
        "                             log_magnitude, real_rank, imag_rank, quadrant))"
      ],
      "metadata": {
        "id": "TMaz9eTTutll"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Visualization Functions (visualize_constellation, visualize_decision_tree, plot_confusion_matrix, plot_cross_performance, plot_classifier_comparison, plot_feature_importance):\n",
        "\n",
        "visualize_constellation(): Plots the received (noisy) QAM-16 constellation points, color-coded by their true labels.\n",
        "visualize_decision_tree(): Visualizes the structure of a trained decision tree classifier. Requires graphviz to be installed for more complex trees.\n",
        "plot_confusion_matrix(): Generates and displays a confusion matrix, which shows the counts of true vs. predicted labels.\n",
        "plot_cross_performance(): Visualizes a heatmap showing the accuracy of a model trained on one noise type and tested on another.\n",
        "plot_classifier_comparison(): Creates a bar plot comparing the accuracy of different classifier models on the combined noise dataset.\n",
        "plot_feature_importance(): Displays a bar plot showing the importance of each feature as determined by a trained classifier (if the classifier supports feature importance)."
      ],
      "metadata": {
        "id": "rpY10GShKCeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization ---\n",
        "def visualize_constellation(X_complex: np.ndarray, y: np.ndarray, title: str = \"QAM-16 Constellation\", filename_suffix: str = \"\") -> None:\n",
        "    \"\"\"Visualizes the QAM-16 constellation points.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(16):\n",
        "        mask = y == i\n",
        "        plt.scatter(X_complex[mask].real, X_complex[mask].imag, label=f'{i}', alpha=0.6)\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('Real Part')\n",
        "    plt.ylabel('Imaginary Part')\n",
        "    plt.title(title)\n",
        "    plt.legend(fontsize='small')\n",
        "    plt.savefig(f'qam16_constellation_{title.replace(\" \", \"_\").lower()}{filename_suffix}.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "AE-458-zMyDv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate and visualize the QAM-16 constellation with different noise types.\"\"\"\n",
        "    num_samples = 1000\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples)\n",
        "    constellation, original_labels = generate_qam16_constellation()\n",
        "    original_labels_array = np.array(list(original_labels.values()))\n",
        "\n",
        "    print(\"--- Visualizing QAM-16 Constellations ---\")\n",
        "\n",
        "    # Visualize the clean constellation\n",
        "    visualize_constellation(constellation, original_labels_array, title=\"Clean QAM-16 Constellation\")\n",
        "    print(\"Saved: qam16_constellation_clean_qam-16_constellation.png\")\n",
        "\n",
        "    # Visualize constellations with different noise types\n",
        "    for noise_type, data in datasets.items():\n",
        "        visualize_constellation(data['complex'], labels, title=f\"{noise_type} QAM-16 Constellation\")\n",
        "        print(f\"Saved: qam16_constellation_{noise_type.lower()}_qam-16_constellation.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHELErPzR0Et",
        "outputId": "27af7c19-b309-46c4-de71-e920104944d3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Visualizing QAM-16 Constellations ---\n",
            "Saved: qam16_constellation_clean_qam-16_constellation.png\n",
            "Saved: qam16_constellation_clean_qam-16_constellation.png\n",
            "Saved: qam16_constellation_gaussian_qam-16_constellation.png\n",
            "Saved: qam16_constellation_impulse_qam-16_constellation.png\n",
            "Saved: qam16_constellation_combined_qam-16_constellation.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_decision_tree(clf: DecisionTreeClassifier, feature_names: list[str], class_names: list[str], title: str = \"Decision Tree\") -> None:\n",
        "    \"\"\"Visualizes the decision tree.\"\"\"\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    tree.plot_tree(clf, feature_names=feature_names, class_names=class_names, filled=True, rounded=True, fontsize=10)\n",
        "    plt.title(title)\n",
        "    plt.savefig(f'qam16_decision_tree_{title.replace(\" \", \"_\").lower()}.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "UTMKn8psGl_o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate a dataset, train a Decision Tree, and visualize it.\"\"\"\n",
        "    num_samples = 2000\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples, noise_types={\"Gaussian\": {\"gaussian\": True, \"impulse\": False, \"snr_db_range\": (15, 20)}})\n",
        "\n",
        "    # Use the Gaussian noisy dataset for training\n",
        "    gaussian_data = datasets.get(\"Gaussian\")\n",
        "    if gaussian_data:\n",
        "        X = gaussian_data['features']\n",
        "        y = labels\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Initialize and train the Decision Tree classifier\n",
        "        clf = DecisionTreeClassifier(max_depth=5)  # You can adjust hyperparameters\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Decision Tree Accuracy on Test Set: {accuracy:.4f}\")\n",
        "\n",
        "        # Define feature names and class names\n",
        "        feature_names = [\"real\", \"imag\", \"magnitude\", \"phase\", \"log_magnitude\", \"real_rank\", \"imag_rank\", \"quadrant\"]\n",
        "        class_names = [str(i) for i in range(16)]  # QAM-16 has 16 classes\n",
        "\n",
        "        # Visualize the trained Decision Tree\n",
        "        visualize_decision_tree(clf, feature_names=feature_names, class_names=class_names, title=\"QAM-16 Decision Tree (Gaussian Noise)\")\n",
        "    else:\n",
        "        print(\"Error: Gaussian noisy dataset not found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT6yO_ueTnmS",
        "outputId": "8856ac33-e76e-4798-e127-18c0306cb514"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy on Test Set: 0.8017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray, title: str = \"Confusion Matrix\") -> np.ndarray:\n",
        "    \"\"\"Plots the confusion matrix.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.arange(16), yticklabels=np.arange(16))\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(f'qam16_confusion_matrix_{title.replace(\" \", \"_\").lower()}.png')\n",
        "    plt.close()\n",
        "    return cm\n",
        "\n",
        "    print(f\"Confusion matrix saved to: qam16_confusion_matrix_{title.replace(' ', '_').lower()}.png\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        ""
      ],
      "metadata": {
        "id": "IAWj-eFfHfzN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate a dataset, train a Decision Tree, make predictions, and plot the confusion matrix.\"\"\"\n",
        "    num_samples = 2000\n",
        "    noise_type = \"Gaussian\"\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples, noise_types={noise_type: {\"gaussian\": True, \"impulse\": False, \"snr_db_range\": (15, 20)}})\n",
        "\n",
        "    gaussian_data = datasets.get(noise_type)\n",
        "    if gaussian_data:\n",
        "        X = gaussian_data['features']\n",
        "        y = labels\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Decision Tree Accuracy on Test Set ({noise_type} Noise): {accuracy:.4f}\")\n",
        "\n",
        "        plot_confusion_matrix(y_test, y_pred, title=f\"Confusion Matrix (Decision Tree, {noise_type} Noise)\")\n",
        "    else:\n",
        "        print(f\"Error: {noise_type} noisy dataset not found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3MwV3bhUHWr",
        "outputId": "38b3468b-9e71-4161-d6fd-f8fde0b45b99"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy on Test Set (Gaussian Noise): 0.8083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cross_performance(cross_performance: Dict[str, Dict[str, float]]) -> None:\n",
        "    \"\"\"Plots the matrix of model performance across different noise types.\"\"\"\n",
        "    noise_types = list(cross_performance.keys())\n",
        "    matrix = np.array([[cross_performance[train][test] for test in noise_types] for train in noise_types])\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(matrix, annot=True, fmt='.1f', cmap='YlGn', xticklabels=noise_types, yticklabels=noise_types)\n",
        "    plt.title('Cross-Performance Matrix (Accuracy %)')\n",
        "    plt.xlabel('Testing Noise Type')\n",
        "    plt.ylabel('Training Noise Type')\n",
        "    plt.savefig('qam16_cross_performance_matrix.png')\n",
        "    plt.close()\n",
        "    print(\"Cross-Performance Matrix plot saved to: qam16_cross_performance_matrix.png\")\n",
        "    print(\"Cross-Performance Data:\")\n",
        "    for train_type, test_results in cross_performance.items():\n",
        "        print(f\"  Trained on {train_type}:\")\n",
        "        for test_type, accuracy in test_results.items():\n",
        "            print(f\"    Tested on {test_type}: {accuracy:.1f}%\")\n"
      ],
      "metadata": {
        "id": "IhrFeNAOusK1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate datasets, train a Decision Tree on each, and evaluate cross-performance.\"\"\"\n",
        "    num_samples = 1000\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples)\n",
        "    noise_types = list(datasets.keys())\n",
        "    cross_performance = {train_type: {} for train_type in noise_types}\n",
        "\n",
        "    print(\"--- Cross-Performance Evaluation ---\")\n",
        "\n",
        "    for train_type in noise_types:\n",
        "        train_data = datasets[train_type]['features']\n",
        "        train_labels = labels\n",
        "\n",
        "        # Train a Decision Tree classifier\n",
        "        clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "        clf.fit(train_data, train_labels)\n",
        "        print(f\"\\nTrained Decision Tree on: {train_type}\")\n",
        "\n",
        "        for test_type in noise_types:\n",
        "            test_data = datasets[test_type]['features']\n",
        "            test_labels = labels\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = clf.predict(test_data)\n",
        "            accuracy = accuracy_score(test_labels, y_pred) * 100\n",
        "            cross_performance[train_type][test_type] = accuracy\n",
        "            print(f\"  Evaluated on {test_type}: Accuracy = {accuracy:.1f}%\")\n",
        "\n",
        "    print(\"\\n--- Cross-Performance Matrix ---\")\n",
        "    plot_cross_performance(cross_performance)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDTmCmNEUfwn",
        "outputId": "e6583868-cf68-4f5e-8bcb-928c1b290b5f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cross-Performance Evaluation ---\n",
            "\n",
            "Trained Decision Tree on: Clean\n",
            "  Evaluated on Clean: Accuracy = 100.0%\n",
            "  Evaluated on Gaussian: Accuracy = 96.5%\n",
            "  Evaluated on Impulse: Accuracy = 94.6%\n",
            "  Evaluated on Combined: Accuracy = 91.8%\n",
            "\n",
            "Trained Decision Tree on: Gaussian\n",
            "  Evaluated on Clean: Accuracy = 99.2%\n",
            "  Evaluated on Gaussian: Accuracy = 100.0%\n",
            "  Evaluated on Impulse: Accuracy = 94.6%\n",
            "  Evaluated on Combined: Accuracy = 91.0%\n",
            "\n",
            "Trained Decision Tree on: Impulse\n",
            "  Evaluated on Clean: Accuracy = 99.4%\n",
            "  Evaluated on Gaussian: Accuracy = 82.8%\n",
            "  Evaluated on Impulse: Accuracy = 99.8%\n",
            "  Evaluated on Combined: Accuracy = 79.0%\n",
            "\n",
            "Trained Decision Tree on: Combined\n",
            "  Evaluated on Clean: Accuracy = 96.6%\n",
            "  Evaluated on Gaussian: Accuracy = 93.1%\n",
            "  Evaluated on Impulse: Accuracy = 95.5%\n",
            "  Evaluated on Combined: Accuracy = 99.6%\n",
            "\n",
            "--- Cross-Performance Matrix ---\n",
            "Cross-Performance Matrix plot saved to: qam16_cross_performance_matrix.png\n",
            "Cross-Performance Data:\n",
            "  Trained on Clean:\n",
            "    Tested on Clean: 100.0%\n",
            "    Tested on Gaussian: 96.5%\n",
            "    Tested on Impulse: 94.6%\n",
            "    Tested on Combined: 91.8%\n",
            "  Trained on Gaussian:\n",
            "    Tested on Clean: 99.2%\n",
            "    Tested on Gaussian: 100.0%\n",
            "    Tested on Impulse: 94.6%\n",
            "    Tested on Combined: 91.0%\n",
            "  Trained on Impulse:\n",
            "    Tested on Clean: 99.4%\n",
            "    Tested on Gaussian: 82.8%\n",
            "    Tested on Impulse: 99.8%\n",
            "    Tested on Combined: 79.0%\n",
            "  Trained on Combined:\n",
            "    Tested on Clean: 96.6%\n",
            "    Tested on Gaussian: 93.1%\n",
            "    Tested on Impulse: 95.5%\n",
            "    Tested on Combined: 99.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classifier_comparison(results: Dict[str, float]) -> None:\n",
        "    \"\"\"Plots the comparison of different classifier accuracies.\"\"\"\n",
        "    names = list(results.keys())\n",
        "    accuracies = list(results.values())\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(len(names)), accuracies)\n",
        "    plt.xticks(range(len(names)), names, rotation=45, ha='right')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Classifier Performance Comparison')\n",
        "    plt.ylim(0, 100)\n",
        "    plt.tight_layout()\n",
        "    for i, v in enumerate(accuracies):\n",
        "        plt.text(i, v + 1, f\"{v:.1f}%\", ha='center')\n",
        "    plt.savefig('qam16_classifier_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Classifier comparison plot saved to: qam16_classifier_comparison.png\")\n",
        "    print(\"Classifier Accuracies:\")\n",
        "    for name, accuracy in results.items():\n",
        "        print(f\"  {name}: {accuracy:.1f}%\")"
      ],
      "metadata": {
        "id": "XThSylMjHg9E"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate a dataset and compare the performance of different classifiers.\"\"\"\n",
        "    num_samples = 1000\n",
        "    noise_type = \"Gaussian_Moderate\"  # Choose a noise type for comparison\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples, noise_types={\n",
        "        noise_type: {\"gaussian\": True, \"impulse\": False, \"snr_db_range\": (18, 22)}\n",
        "    })\n",
        "\n",
        "    data = datasets.get(noise_type)\n",
        "    if data:\n",
        "        X = data['features']\n",
        "        y = labels\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        classifiers = {\n",
        "            \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=42),\n",
        "\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        print(f\"--- Classifier Comparison on {noise_type} Noise ---\")\n",
        "        for name, clf in classifiers.items():\n",
        "            clf.fit(X_train, y_train)\n",
        "            y_pred = clf.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "            results[name] = accuracy\n",
        "            print(f\"{name}: Accuracy = {accuracy:.1f}%\")\n",
        "\n",
        "        print(\"\\n--- Classifier Performance Comparison ---\")\n",
        "        plot_classifier_comparison(results)\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: {noise_type} dataset not found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge6_6KQMVfIK",
        "outputId": "c5ea83de-2f36-4d84-a350-aadd8cc63f9d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Classifier Comparison on Gaussian_Moderate Noise ---\n",
            "Decision Tree: Accuracy = 99.3%\n",
            "\n",
            "--- Classifier Performance Comparison ---\n",
            "Classifier comparison plot saved to: qam16_classifier_comparison.png\n",
            "Classifier Accuracies:\n",
            "  Decision Tree: 99.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(clf: Any, feature_names: list[str]) -> None:\n",
        "    \"\"\"Plots the feature importances of a trained classifier.\"\"\"\n",
        "    if hasattr(clf, 'feature_importances_'):\n",
        "        importances = clf.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.bar(range(len(feature_names)), importances[indices])\n",
        "        plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
        "        plt.xlabel('Features')\n",
        "        plt.ylabel('Importance')\n",
        "        plt.title('Feature Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('qam16_feature_importance.png')\n",
        "        plt.close()\n",
        "    else:\n",
        "        print(\"Classifier does not have feature_importances_ attribute.\")\n"
      ],
      "metadata": {
        "id": "ZPDT2UYPHuFp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to generate a dataset, train a Decision Tree, and plot feature importance.\"\"\"\n",
        "    num_samples = 1000\n",
        "    noise_type = \"Gaussian_Moderate\"  # Choose a noise type\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples, noise_types={\n",
        "        noise_type: {\"gaussian\": True, \"impulse\": False, \"snr_db_range\": (18, 22)}\n",
        "    })\n",
        "\n",
        "    data = datasets.get(noise_type)\n",
        "    if data:\n",
        "        X = data['features']\n",
        "        y = labels\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Train a Decision Tree classifier (it has feature_importances_)\n",
        "        clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Define feature names (must match the order in extract_features)\n",
        "        feature_names = [\"real\", \"imag\", \"magnitude\", \"phase\", \"log_magnitude\", \"real_rank\", \"imag_rank\", \"quadrant\"]\n",
        "\n",
        "        # Plot feature importance\n",
        "        plot_feature_importance(clf, feature_names)\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: {noise_type} dataset not found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "f4fehjpLXv3f"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Training and Evaluation ---\n",
        "def train_and_evaluate_classifier(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray, classifier: Any) -> Tuple[Any, float, np.ndarray]:\n",
        "    \"\"\"Trains and evaluates a classifier.\"\"\"\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return classifier, accuracy, y_pred"
      ],
      "metadata": {
        "id": "3ddJsrZW6Mtq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_noise_types(datasets: Dict[str, Dict[str, np.ndarray]], y: np.ndarray, test_size: float = 0.2) -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"Compares decision tree model performance across different noise types.\"\"\"\n",
        "    results = {\"train_on\": {}, \"cross_performance\": {}}\n",
        "\n",
        "    for train_noise, train_data in datasets.items():\n",
        "        print(f\"\\nTraining on {train_noise} noise...\")\n",
        "        X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
        "            train_data[\"features\"], y, test_size=test_size, random_state=42\n",
        "        )\n",
        "        clf = DecisionTreeClassifier(max_depth=12, min_samples_split=8, min_samples_leaf=4, random_state=42)\n",
        "        trained_clf, train_accuracy, _ = train_and_evaluate_classifier(X_train_all, X_test_all, y_train, y_test, clf)\n",
        "        results[\"train_on\"][train_noise] = {\"model\": trained_clf, \"accuracy\": train_accuracy * 100}\n",
        "        print(f\"  Training accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "        noise_accuracies = {}\n",
        "        for test_noise, test_data in datasets.items():\n",
        "            X_test_noise_all = test_data[\"features\"]\n",
        "            _, X_test_noise, _, y_test_consistent = train_test_split(\n",
        "                X_test_noise_all, y, test_size=test_size, random_state=42\n",
        "            )\n",
        "            y_pred_cross = trained_clf.predict(X_test_noise)\n",
        "            cross_accuracy = accuracy_score(y_test_consistent, y_pred_cross)\n",
        "            noise_accuracies[test_noise] = cross_accuracy * 100\n",
        "            print(f\"  Tested on {test_noise} noise: {cross_accuracy * 100:.2f}%\")\n",
        "        results[\"cross_performance\"][train_noise] = noise_accuracies\n",
        "\n",
        "    plot_cross_performance(results[\"cross_performance\"])\n",
        "    return results"
      ],
      "metadata": {
        "id": "VV3OyI-76SKc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume extract_features and generate_dataset functions are defined as in previous examples\n",
        "def extract_features(X_complex: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Placeholder for feature extraction function.\"\"\"\n",
        "    return np.column_stack((X_complex.real, X_complex.imag))\n",
        "\n",
        "def generate_dataset(num_samples: int = 1000, noise_types: Dict[str, Dict[str, Any]] = None) -> Tuple[Dict[str, Dict[str, np.ndarray]], np.ndarray]:\n",
        "    \"\"\"Placeholder for dataset generation function.\"\"\"\n",
        "    if noise_types is None:\n",
        "        noise_types = {\n",
        "            \"Combined\": {\"gaussian\": True, \"impulse\": True, \"snr_db_range\": (18, 22), \"impulse_prob_range\": (0.03, 0.06), \"impulse_amplitude_range\": (2.0, 4.0)}\n",
        "        }\n",
        "    datasets = {}\n",
        "    labels = np.random.randint(0, 16, num_samples)\n",
        "    for noise_name, config in noise_types.items():\n",
        "        complex_signals = np.random.randn(num_samples) + 1j * np.random.randn(num_samples)\n",
        "        features = extract_features(complex_signals)\n",
        "        datasets[noise_name] = {\"complex\": complex_signals, \"features\": features}\n",
        "    return datasets, labels\n",
        "\n",
        "def compare_classifiers(datasets: Dict[str, Dict[str, np.ndarray]], y: np.ndarray, test_size: float = 0.2) -> Dict[str, float]:\n",
        "    \"\"\"Compares different classifier types on the combined noise dataset.\"\"\"\n",
        "    if \"Combined\" not in datasets or \"features\" not in datasets[\"Combined\"]:\n",
        "        print(\"Error: 'Combined' noise dataset with 'features' not found.\")\n",
        "        return {}  # Return an empty dictionary instead of None\n",
        "\n",
        "    X_features = datasets[\"Combined\"][\"features\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=test_size, random_state=42)\n",
        "    classifiers = {\n",
        "        \"Decision Tree (max_depth=8)\": DecisionTreeClassifier(max_depth=8, random_state=42),\n",
        "        \"Decision Tree (max_depth=12)\": DecisionTreeClassifier(max_depth=12, random_state=42),\n",
        "        \"Decision Tree (max_depth=16)\": DecisionTreeClassifier(max_depth=16, random_state=42),\n",
        "        \"Random Forest (10 trees)\": RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    }\n",
        "    results = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[name] = accuracy\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to generate a dataset and compare different classifiers.\"\"\"\n",
        "    num_samples = 2000\n",
        "    noise_types_to_generate = {\n",
        "        \"Combined\": {\"gaussian\": True, \"impulse\": True, \"snr_db_range\": (18, 22), \"impulse_prob_range\": (0.03, 0.06), \"impulse_amplitude_range\": (2.0, 4.0)}\n",
        "    }\n",
        "    datasets, labels = generate_dataset(num_samples=num_samples, noise_types=noise_types_to_generate)\n",
        "\n",
        "    if labels.shape[0] != num_samples:\n",
        "        print(f\"Warning: Number of labels ({labels.shape[0]}) does not match the expected number of samples ({num_samples}).\")\n",
        "\n",
        "    comparison_results = compare_classifiers(datasets, labels, test_size=0.3)\n",
        "\n",
        "    print(\"--- Classifier Comparison Results (Combined Noise) ---\")\n",
        "    if comparison_results:  # Check if comparison_results is not None or empty\n",
        "        for name, accuracy in comparison_results.items():\n",
        "            print(f\"{name}: Accuracy = {accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"No classifier comparison results to display.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWjX4rM0ZX2M",
        "outputId": "00c8a50d-fe8d-45c5-821c-181f7d24501f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Classifier Comparison Results (Combined Noise) ---\n",
            "Decision Tree (max_depth=8): Accuracy = 0.0550\n",
            "Decision Tree (max_depth=12): Accuracy = 0.0483\n",
            "Decision Tree (max_depth=16): Accuracy = 0.0550\n",
            "Random Forest (10 trees): Accuracy = 0.0533\n"
          ]
        }
      ]
    }
  ]
}