{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/SDR-ML-Project/blob/fix-modulation-function/QAMReceiverV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7L-Ly9L0tyM"
      },
      "source": [
        "Function to convert binary data to QAM16 constellations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WN2UEDeQ9Wry",
        "outputId": "3004f717-2ed5-4f0f-839c-47a1f1c8d77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\anees\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr1JBlR5M6Us"
      },
      "source": [
        "16QAM Constellation Modulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_2GERHoIxaP",
        "outputId": "67ae04c8-85df-457e-8551-96788ed32920"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "Used https://dsplog.com/2008/06/01/binary-to-gray-code-for-16qam/ for mappings. When tested, the function works and\n",
        "the binary is correctly mapped to its correspondingcomplex number based on the constellation. To check, uncomment\n",
        "the last line in the cell which prints a test run of the function.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def modulator(binary_data, M):\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # defining the real and imaginary PAM constellation for 16-QAM\n",
        "    alphaRe = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "    alphaIm = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "\n",
        "    # taking b0b1 for real\n",
        "    ipDecRe = np.array([int(''.join(map(str, b[:k//2])), 2) for b in binary_data])\n",
        "    ipGrayDecRe = ipDecRe ^ (ipDecRe >> 1)\n",
        "\n",
        "    # taking b2b3 for imaginary\n",
        "    ipDecIm = np.array([int(''.join(map(str, b[k//2:])), 2) for b in binary_data])\n",
        "    ipGrayDecIm = ipDecIm ^ (ipDecIm >> 1)\n",
        "\n",
        "    # mapping the Gray coded symbols into constellation\n",
        "    modRe = alphaRe[ipGrayDecRe]\n",
        "    modIm = alphaIm[ipGrayDecIm]\n",
        "\n",
        "    # complex constellation\n",
        "    mod = modRe + 1j * modIm\n",
        "\n",
        "    return mod\n",
        "\n",
        "def generate_qam_symbols(M=16, num_symbols=1000):\n",
        "    # 4 bits per symbol\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # Generate random binary data\n",
        "    random_bits = np.random.randint(0, 2, num_symbols * k)\n",
        "\n",
        "    # Reshape to match modulator input\n",
        "    binary_data = random_bits.reshape((-1, k))\n",
        "\n",
        "    # Modulate Binary Data\n",
        "    modulated_symbols = modulator(binary_data, M)\n",
        "\n",
        "    return modulated_symbols, binary_data\n",
        "#print(generate_qam_symbols(16,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVRNEKFJ0qCB"
      },
      "source": [
        "Adding noise to 16QAM signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "HNF_9MFqwuSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def add_awgn(qam_symbols, snr_db):\n",
        "    \"\"\"\n",
        "    Adds Additive White Gaussian Noise (AWGN) to QAM symbols.\n",
        "\n",
        "    Parameters:\n",
        "        qam_symbols (numpy array): The transmitted QAM symbols (complex numbers).\n",
        "        snr_db (float): Signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Noisy QAM symbols.\n",
        "    \"\"\"\n",
        "    # Calculate signal power\n",
        "    signal_power = np.mean(np.abs(qam_symbols) ** 2)\n",
        "\n",
        "    # Compute noise power based on SNR (convert dB to linear scale)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "\n",
        "    # Generate AWGN noise\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*qam_symbols.shape) + 1j * np.random.randn(*qam_symbols.shape))\n",
        "\n",
        "    # Add noise to the symbols\n",
        "    noisy_qam_symbols = qam_symbols + noise\n",
        "    return noisy_qam_symbols\n",
        "\n",
        "\n",
        "# Generate 16QAM symbols\n",
        "M = 16\n",
        "num_symbols = 1000\n",
        "qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "\n",
        "#Signal to noise ratio in dB\n",
        "#High signal to noise ratio is good, low is bad\n",
        "snr_db = 15\n",
        "\n",
        "\n",
        "# Add noise to QAM symbols\n",
        "noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "\n",
        "df = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.drop(['index'],axis=1,inplace=True)\n",
        "\n",
        "#Getting data of different noise levels (data augmentation to prevent overfitting)\n",
        "for i in range(15, 55, 5):\n",
        "  M = 16\n",
        "  num_symbols = 2000\n",
        "  qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "  snr_db = i\n",
        "  noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "  df1 = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "  df1.reset_index(inplace=True)\n",
        "  df1.drop(['index'],axis=1,inplace=True)\n",
        "  df = pd.concat([df, df1])\n",
        "\n",
        "  #Plot Constellations (Before and After Noise)\n",
        "  # plt.figure(figsize=(10,5))\n",
        "  # plt.subplot(1,2,2)\n",
        "  # plt.scatter(noisy_qam.real, noisy_qam.imag, alpha=0.5, label=\"Noisy\")\n",
        "  # plt.title(f\"Signal to Noise Ratio = {snr_db} dB)\")\n",
        "  # plt.xlabel(\"In-phase (I)\")\n",
        "  # plt.ylabel(\"Quadrature (Q)\")\n",
        "  # plt.grid()\n",
        "\n",
        "  #plt.show()\n",
        "df = df.rename(columns={'features': 'binary','target':'complex'})\n",
        "#To save as CSV\n",
        "df.to_csv('dataWithNoise.csv', index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKPQnpx0kaq"
      },
      "source": [
        "Build Neural Network\n",
        "\n",
        "X = Complex\n",
        "\n",
        "y = Binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a12Dw20oPB",
        "outputId": "ddd8034d-57e7-40b4-ca59-a05b777a6360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anees\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4346 - loss: 1.8945 - val_accuracy: 0.9838 - val_loss: 0.4247\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.4420 - val_accuracy: 0.9912 - val_loss: 0.0619\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9400 - loss: 0.2441 - val_accuracy: 0.9930 - val_loss: 0.0304\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1551 - val_accuracy: 0.9926 - val_loss: 0.0233\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1119 - val_accuracy: 0.9926 - val_loss: 0.0233\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0977 - val_accuracy: 0.9923 - val_loss: 0.0215\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0782 - val_accuracy: 0.9912 - val_loss: 0.0217\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0767 - val_accuracy: 0.9937 - val_loss: 0.0222\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0629 - val_accuracy: 0.9923 - val_loss: 0.0209\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0604 - val_accuracy: 0.9926 - val_loss: 0.0203\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0598 - val_accuracy: 0.9934 - val_loss: 0.0206\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0591 - val_accuracy: 0.9901 - val_loss: 0.0334\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0647 - val_accuracy: 0.9923 - val_loss: 0.0200\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0585 - val_accuracy: 0.9923 - val_loss: 0.0204\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0525 - val_accuracy: 0.9937 - val_loss: 0.0230\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0513 - val_accuracy: 0.9934 - val_loss: 0.0205\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0508 - val_accuracy: 0.9923 - val_loss: 0.0254\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0416 - val_accuracy: 0.9930 - val_loss: 0.0252\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0509 - val_accuracy: 0.9926 - val_loss: 0.0237\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0415 - val_accuracy: 0.9919 - val_loss: 0.0333\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0164\n",
            "Test Accuracy: 99.50%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Target variable (binary data)\n",
        "y = df['binary'].values\n",
        "# Convert each element of y to a NumPy array\n",
        "y = np.array([np.array(yi) for yi in y])\n",
        "#Reshape to 4 bits/symbol (-1 means numpy will figure out how many rows are needed)\n",
        "y = y.reshape(-1, 4)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Manually convert 4-bit binary to integer (0-15)\n",
        "y = np.array([int(\"\".join(str(bit) for bit in row), 2) for row in y])\n",
        "\n",
        "# One-hot encoding for 16 classes\n",
        "y = to_categorical(y, num_classes=16)\n",
        "\n",
        "\n",
        "# Features (complex data)\n",
        "X = df['complex'].values\n",
        "X = np.array([np.array(xi) for xi in X])\n",
        "\n",
        "# Reshape to (n_samples, 2) for real and imaginary parts\n",
        "X = [[x.real, x.imag] for x in X]\n",
        "X = np.array(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(2,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # 16 neurons for 16 different possibilities (0000 - 1111)\n",
        "    Dense(16, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py1ldtIseMqg",
        "outputId": "dd7ec307-8dbc-48c7-ae1d-cbf56eb697bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
            "Complex Input:  [[ 2.5 -3. ]\n",
            " [ 1.  -3. ]\n",
            " [ 3.  -1. ]\n",
            " [-1.   3. ]]\n",
            "Model Predictions:  ['1000', '1100', '1001', '1100']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>(-3, -3)</th>\n",
              "      <th>(-3,-1)</th>\n",
              "      <th>(-3, 1)</th>\n",
              "      <th>(-3, 3)</th>\n",
              "      <th>(-1, -3)</th>\n",
              "      <th>(-1, -1)</th>\n",
              "      <th>(-1, 1)</th>\n",
              "      <th>(-1, 3)</th>\n",
              "      <th>(1, -3)</th>\n",
              "      <th>(1, -1)</th>\n",
              "      <th>(1, 1)</th>\n",
              "      <th>(1, 3)</th>\n",
              "      <th>(3, -3)</th>\n",
              "      <th>(3, -1)</th>\n",
              "      <th>(3, 1</th>\n",
              "      <th>(3, 3)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>0000</th>\n",
              "      <th>0001</th>\n",
              "      <th>0011</th>\n",
              "      <th>0010</th>\n",
              "      <th>0100</th>\n",
              "      <th>0101</th>\n",
              "      <th>0111</th>\n",
              "      <th>0110</th>\n",
              "      <th>1100</th>\n",
              "      <th>1101</th>\n",
              "      <th>1111</th>\n",
              "      <th>1110</th>\n",
              "      <th>1000</th>\n",
              "      <th>1001</th>\n",
              "      <th>1011</th>\n",
              "      <th>1010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [((-3, -3), 0000), ((-3,-1), 0001), ((-3, 1), 0011), ((-3, 3), 0010), ((-1, -3), 0100), ((-1, -1), 0101), ((-1, 1), 0111), ((-1, 3), 0110), ((1, -3), 1100), ((1, -1), 1101), ((1, 1), 1111), ((1, 3), 1110), ((3, -3), 1000), ((3, -1), 1001), ((3, 1, 1011), ((3, 3), 1010)]\n",
              "Index: []"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_pred = np.array([[2.5, -3], [1, -3], [3, -1], [-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "# Assuming model.predict(X_pred) gives some output\n",
        "temp = model.predict(X_pred)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# Find the index of the max value in each prediction\n",
        "for x in range(len(temp)):\n",
        "    max_val = max(temp[x])\n",
        "    predictions.append(np.where(temp[x] == max_val)[0][0])\n",
        "print(\"Complex Input: \", X_pred)\n",
        "\n",
        "\n",
        "binarylist = []\n",
        "for num in predictions:\n",
        "    binary = \"\"\n",
        "    if num == 0:  \n",
        "        binary = \"0000\"\n",
        "    else:\n",
        "        while num > 0:\n",
        "            binary = str(num % 2) + binary  \n",
        "            num //= 2 \n",
        "    if(len(binary)) < 4:\n",
        "        binary += \"0\"\n",
        "    binarylist.append(binary)\n",
        "print(\"Model Predictions: \", binarylist)\n",
        "comlex = [\"(-3, -3)\",\"(-3,-1)\",\"(-3, 1)\",\"(-3, 3)\",\"(-1, -3)\",\"(-1, -1)\",\"(-1, 1)\",\"(-1, 3)\",\"(1, -3)\",\"(1, -1)\",\"(1, 1)\",\"(1, 3)\",\"(3, -3)\",\"(3, -1)\",\"(3, 1\",\"(3, 3)\"]\n",
        "bin = [\"0000\",\"0001\",\"0011\",\"0010\",\"0100\",\"0101\",\"0111\",\"0110\",\"1100\",\"1101\",\"1111\",\"1110\",\"1000\",\"1001\",\"1011\",\"1010\"]\n",
        "\n",
        "#Making df to help test predictions\n",
        "compare = pd.DataFrame(columns=[comlex, bin])\n",
        "compare\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPphO4M0rKaJ1POkS9GCz3A",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
