{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaGsgl2MMY7mQ0sCjJKzrd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/SDR-ML-Project/blob/editNN/QAMReceiverV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert binary data to QAM16 constellations"
      ],
      "metadata": {
        "id": "D7L-Ly9L0tyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN2UEDeQ9Wry",
        "outputId": "3004f717-2ed5-4f0f-839c-47a1f1c8d77c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16QAM Constellation Modulator"
      ],
      "metadata": {
        "id": "wr1JBlR5M6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "Used https://dsplog.com/2008/06/01/binary-to-gray-code-for-16qam/ for mappings. When tested, the function works and the binary is correctly mapped to its corresponding\n",
        "complex number based on the constellation. To check, uncomment the last line in the cell which prints a test run of the function.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def modulator(binary_data, M):\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # defining the real and imaginary PAM constellation for 16-QAM\n",
        "    alphaRe = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "    alphaIm = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "\n",
        "    # taking b0b1 for real\n",
        "    ipDecRe = np.array([int(''.join(map(str, b[:k//2])), 2) for b in binary_data])\n",
        "    ipGrayDecRe = ipDecRe ^ (ipDecRe >> 1)\n",
        "\n",
        "    # taking b2b3 for imaginary\n",
        "    ipDecIm = np.array([int(''.join(map(str, b[k//2:])), 2) for b in binary_data])\n",
        "    ipGrayDecIm = ipDecIm ^ (ipDecIm >> 1)\n",
        "\n",
        "    # mapping the Gray coded symbols into constellation\n",
        "    modRe = alphaRe[ipGrayDecRe]\n",
        "    modIm = alphaIm[ipGrayDecIm]\n",
        "\n",
        "    # complex constellation\n",
        "    mod = modRe + 1j * modIm\n",
        "\n",
        "    return mod\n",
        "\n",
        "def generate_qam_symbols(M=16, num_symbols=1000):\n",
        "    # 4 bits per symbol\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # Generate random binary data\n",
        "    random_bits = np.random.randint(0, 2, num_symbols * k)\n",
        "\n",
        "    # Reshape to match modulator input\n",
        "    binary_data = random_bits.reshape((-1, k))\n",
        "\n",
        "    # Modulate Binary Data\n",
        "    modulated_symbols = modulator(binary_data, M)\n",
        "\n",
        "    return modulated_symbols, binary_data\n",
        "#print(generate_qam_symbols(16,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_2GERHoIxaP",
        "outputId": "67ae04c8-85df-457e-8551-96788ed32920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([-1.+3.j,  1.-1.j,  1.+3.j,  3.+3.j, -3.+3.j]), array([[0, 1, 1, 0],\n",
            "       [1, 1, 0, 1],\n",
            "       [1, 1, 1, 0],\n",
            "       [1, 0, 1, 0],\n",
            "       [0, 0, 1, 0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding noise to 16QAM signals"
      ],
      "metadata": {
        "id": "mVRNEKFJ0qCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def add_awgn(qam_symbols, snr_db):\n",
        "    \"\"\"\n",
        "    Adds Additive White Gaussian Noise (AWGN) to QAM symbols.\n",
        "\n",
        "    Parameters:\n",
        "        qam_symbols (numpy array): The transmitted QAM symbols (complex numbers).\n",
        "        snr_db (float): Signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Noisy QAM symbols.\n",
        "    \"\"\"\n",
        "    # Calculate signal power\n",
        "    signal_power = np.mean(np.abs(qam_symbols) ** 2)\n",
        "\n",
        "    # Compute noise power based on SNR (convert dB to linear scale)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "\n",
        "    # Generate AWGN noise\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*qam_symbols.shape) + 1j * np.random.randn(*qam_symbols.shape))\n",
        "\n",
        "    # Add noise to the symbols\n",
        "    noisy_qam_symbols = qam_symbols + noise\n",
        "    return noisy_qam_symbols\n",
        "\n",
        "\n",
        "# Generate 16QAM symbols\n",
        "M = 16\n",
        "num_symbols = 1000\n",
        "qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "\n",
        "#Signal to noise ratio in dB\n",
        "#High signal to noise ratio is good, low is bad\n",
        "snr_db = 15\n",
        "\n",
        "\n",
        "# Add noise to QAM symbols\n",
        "noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "\n",
        "df = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.drop(['index'],axis=1,inplace=True)\n",
        "\n",
        "#Getting data of different noise levels (data augmentation to prevent overfitting)\n",
        "for i in range(15, 55, 5):\n",
        "  M = 16\n",
        "  num_symbols = 2000\n",
        "  qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "  snr_db = i\n",
        "  noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "  df1 = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "  df1.reset_index(inplace=True)\n",
        "  df1.drop(['index'],axis=1,inplace=True)\n",
        "  df = pd.concat([df, df1])\n",
        "\n",
        "  #Plot Constellations (Before and After Noise)\n",
        "  # plt.figure(figsize=(10,5))\n",
        "  # plt.subplot(1,2,2)\n",
        "  # plt.scatter(noisy_qam.real, noisy_qam.imag, alpha=0.5, label=\"Noisy\")\n",
        "  # plt.title(f\"Signal to Noise Ratio = {snr_db} dB)\")\n",
        "  # plt.xlabel(\"In-phase (I)\")\n",
        "  # plt.ylabel(\"Quadrature (Q)\")\n",
        "  # plt.grid()\n",
        "\n",
        "  #plt.show()\n",
        "df = df.rename(columns={'features': 'binary','target':'complex'})\n",
        "#To save as CSV\n",
        "df.to_csv('dataWithNoise.csv', index = False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HNF_9MFqwuSN",
        "collapsed": true
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Neural Network\n",
        "\n",
        "X = Complex\n",
        "\n",
        "y = Binary converted to Decimal"
      ],
      "metadata": {
        "id": "omKPQnpx0kaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Target variable (binary data)\n",
        "y = df['binary'].values\n",
        "print(y[:5])\n",
        "#Convert y from binary to decimal values\n",
        "decimal_array = []\n",
        "for binary_number in y:\n",
        "  decimal_value = 0\n",
        "  for i, bit in enumerate(reversed(binary_number)):\n",
        "    decimal_value += bit * (2**i)\n",
        "  decimal_array.append(decimal_value)\n",
        "y = np.array(decimal_array)\n",
        "#Testing to see if conversion is correct, it is\n",
        "print(y[:5])\n",
        "\n",
        "\n",
        "# Features (complex data)\n",
        "X = df['complex'].values\n",
        "X = np.array([np.array(xi) for xi in X])\n",
        "\n",
        "# Reshape to (n_samples, 2) for real and imaginary parts\n",
        "X = [[x.real, x.imag] for x in X]\n",
        "X = np.array(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(2,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(16, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a12Dw20oPB",
        "outputId": "ec60b370-80b5-4d9c-dd45-8d9384a087da"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([0, 1, 0, 1]) list([1, 1, 1, 0]) list([1, 1, 1, 0])\n",
            " list([0, 1, 1, 1]) list([0, 0, 0, 0])]\n",
            "[ 5 14 14  7  0]\n",
            "[[-3.22934144  2.99795137]\n",
            " [-0.99280508 -1.00464553]\n",
            " [ 1.06486763  3.0417588 ]\n",
            " ...\n",
            " [-3.00713923  3.00824455]\n",
            " [-2.70176009  0.4389824 ]\n",
            " [-0.91505457 -2.96105393]]\n",
            "[ 2  5 14 ...  2  3  4]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(32, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0639 - loss: 8.9387e-07 - val_accuracy: 0.0747 - val_loss: 8.9572e-07\n",
            "Epoch 2/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0654 - loss: 8.8703e-07 - val_accuracy: 0.0845 - val_loss: 8.9572e-07\n",
            "Epoch 3/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0655 - loss: 8.8796e-07 - val_accuracy: 0.0913 - val_loss: 8.9572e-07\n",
            "Epoch 4/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.0646 - loss: 8.9608e-07 - val_accuracy: 0.0796 - val_loss: 8.9572e-07\n",
            "Epoch 5/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0697 - loss: 8.8573e-07 - val_accuracy: 0.1063 - val_loss: 8.9572e-07\n",
            "Epoch 6/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0654 - loss: 8.9162e-07 - val_accuracy: 0.1037 - val_loss: 8.9572e-07\n",
            "Epoch 7/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0641 - loss: 8.9127e-07 - val_accuracy: 0.0910 - val_loss: 8.9572e-07\n",
            "Epoch 8/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0630 - loss: 8.9681e-07 - val_accuracy: 0.0860 - val_loss: 8.9572e-07\n",
            "Epoch 9/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0661 - loss: 8.8884e-07 - val_accuracy: 0.1072 - val_loss: 8.9572e-07\n",
            "Epoch 10/10\n",
            "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0622 - loss: 8.9092e-07 - val_accuracy: 0.1011 - val_loss: 8.9572e-07\n",
            "\u001b[1m 32/257\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1074 - loss: 9.0434e-07   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m257/257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1128 - loss: 8.8562e-07\n",
            "Test Accuracy: 11.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make NN with last layer w/ 1 neuron\n",
        "\n",
        "Use same training data\n",
        "\n",
        "Save Train and Test as CSV\n",
        "\n",
        "\n",
        "\n",
        "Stage 1: Put the last layer as linear activation, map to 0-15\n",
        "\n",
        "Stage 2: See if we can use decision trees (what accuracy? how does it compare?)\n",
        "\n",
        "Stage 3: Increase size of dataset to 20k"
      ],
      "metadata": {
        "id": "jtXNL51UiiGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = np.array([[3, -3],[1, -3],[3, -1],[-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "predictions = model.predict(X_pred)\n",
        "print(f\"Predictions: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py1ldtIseMqg",
        "outputId": "dd7ec307-8dbc-48c7-ae1d-cbf56eb697bb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    }
  ]
}