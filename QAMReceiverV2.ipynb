{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPphO4M0rKaJ1POkS9GCz3A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/SDR-ML-Project/blob/fix-modulation-function/QAMReceiverV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert binary data to QAM16 constellations"
      ],
      "metadata": {
        "id": "D7L-Ly9L0tyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN2UEDeQ9Wry",
        "outputId": "3004f717-2ed5-4f0f-839c-47a1f1c8d77c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16QAM Constellation Modulator"
      ],
      "metadata": {
        "id": "wr1JBlR5M6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "Used https://dsplog.com/2008/06/01/binary-to-gray-code-for-16qam/ for mappings. When tested, the function works and\n",
        "the binary is correctly mapped to its correspondingcomplex number based on the constellation. To check, uncomment\n",
        "the last line in the cell which prints a test run of the function.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def modulator(binary_data, M):\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # defining the real and imaginary PAM constellation for 16-QAM\n",
        "    alphaRe = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "    alphaIm = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "\n",
        "    # taking b0b1 for real\n",
        "    ipDecRe = np.array([int(''.join(map(str, b[:k//2])), 2) for b in binary_data])\n",
        "    ipGrayDecRe = ipDecRe ^ (ipDecRe >> 1)\n",
        "\n",
        "    # taking b2b3 for imaginary\n",
        "    ipDecIm = np.array([int(''.join(map(str, b[k//2:])), 2) for b in binary_data])\n",
        "    ipGrayDecIm = ipDecIm ^ (ipDecIm >> 1)\n",
        "\n",
        "    # mapping the Gray coded symbols into constellation\n",
        "    modRe = alphaRe[ipGrayDecRe]\n",
        "    modIm = alphaIm[ipGrayDecIm]\n",
        "\n",
        "    # complex constellation\n",
        "    mod = modRe + 1j * modIm\n",
        "\n",
        "    return mod\n",
        "\n",
        "def generate_qam_symbols(M=16, num_symbols=1000):\n",
        "    # 4 bits per symbol\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # Generate random binary data\n",
        "    random_bits = np.random.randint(0, 2, num_symbols * k)\n",
        "\n",
        "    # Reshape to match modulator input\n",
        "    binary_data = random_bits.reshape((-1, k))\n",
        "\n",
        "    # Modulate Binary Data\n",
        "    modulated_symbols = modulator(binary_data, M)\n",
        "\n",
        "    return modulated_symbols, binary_data\n",
        "#print(generate_qam_symbols(16,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_2GERHoIxaP",
        "outputId": "67ae04c8-85df-457e-8551-96788ed32920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([-1.+3.j,  1.-1.j,  1.+3.j,  3.+3.j, -3.+3.j]), array([[0, 1, 1, 0],\n",
            "       [1, 1, 0, 1],\n",
            "       [1, 1, 1, 0],\n",
            "       [1, 0, 1, 0],\n",
            "       [0, 0, 1, 0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding noise to 16QAM signals"
      ],
      "metadata": {
        "id": "mVRNEKFJ0qCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def add_awgn(qam_symbols, snr_db):\n",
        "    \"\"\"\n",
        "    Adds Additive White Gaussian Noise (AWGN) to QAM symbols.\n",
        "\n",
        "    Parameters:\n",
        "        qam_symbols (numpy array): The transmitted QAM symbols (complex numbers).\n",
        "        snr_db (float): Signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Noisy QAM symbols.\n",
        "    \"\"\"\n",
        "    # Calculate signal power\n",
        "    signal_power = np.mean(np.abs(qam_symbols) ** 2)\n",
        "\n",
        "    # Compute noise power based on SNR (convert dB to linear scale)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "\n",
        "    # Generate AWGN noise\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*qam_symbols.shape) + 1j * np.random.randn(*qam_symbols.shape))\n",
        "\n",
        "    # Add noise to the symbols\n",
        "    noisy_qam_symbols = qam_symbols + noise\n",
        "    return noisy_qam_symbols\n",
        "\n",
        "\n",
        "# Generate 16QAM symbols\n",
        "M = 16\n",
        "num_symbols = 1000\n",
        "qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "\n",
        "#Signal to noise ratio in dB\n",
        "#High signal to noise ratio is good, low is bad\n",
        "snr_db = 15\n",
        "\n",
        "\n",
        "# Add noise to QAM symbols\n",
        "noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "\n",
        "df = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.drop(['index'],axis=1,inplace=True)\n",
        "\n",
        "#Getting data of different noise levels (data augmentation to prevent overfitting)\n",
        "for i in range(15, 55, 5):\n",
        "  M = 16\n",
        "  num_symbols = 2000\n",
        "  qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "  snr_db = i\n",
        "  noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "  df1 = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "  df1.reset_index(inplace=True)\n",
        "  df1.drop(['index'],axis=1,inplace=True)\n",
        "  df = pd.concat([df, df1])\n",
        "\n",
        "  #Plot Constellations (Before and After Noise)\n",
        "  # plt.figure(figsize=(10,5))\n",
        "  # plt.subplot(1,2,2)\n",
        "  # plt.scatter(noisy_qam.real, noisy_qam.imag, alpha=0.5, label=\"Noisy\")\n",
        "  # plt.title(f\"Signal to Noise Ratio = {snr_db} dB)\")\n",
        "  # plt.xlabel(\"In-phase (I)\")\n",
        "  # plt.ylabel(\"Quadrature (Q)\")\n",
        "  # plt.grid()\n",
        "\n",
        "  #plt.show()\n",
        "df = df.rename(columns={'features': 'binary','target':'complex'})\n",
        "#To save as CSV\n",
        "df.to_csv('dataWithNoise.csv', index = False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HNF_9MFqwuSN",
        "collapsed": true
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Neural Network\n",
        "\n",
        "X = Complex\n",
        "\n",
        "y = Binary"
      ],
      "metadata": {
        "id": "omKPQnpx0kaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Target variable (binary data)\n",
        "y = df['binary'].values\n",
        "# Convert each element of y to a NumPy array\n",
        "y = np.array([np.array(yi) for yi in y])\n",
        "#Reshape to 4 bits/symbol (-1 means numpy will figure out how many rows are needed)\n",
        "y = y.reshape(-1, 4)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Manually convert 4-bit binary to integer (0-15)\n",
        "y = np.array([int(\"\".join(str(bit) for bit in row), 2) for row in y])\n",
        "\n",
        "# One-hot encoding for 16 classes\n",
        "y = to_categorical(y, num_classes=16)\n",
        "\n",
        "\n",
        "# Features (complex data)\n",
        "X = df['complex'].values\n",
        "X = np.array([np.array(xi) for xi in X])\n",
        "\n",
        "# Reshape to (n_samples, 2) for real and imaginary parts\n",
        "X = [[x.real, x.imag] for x in X]\n",
        "X = np.array(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(2,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # 16 neurons for 16 different possibilities (0000 - 1111)\n",
        "    Dense(16, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a12Dw20oPB",
        "outputId": "ddd8034d-57e7-40b4-ca59-a05b777a6360"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.60766195  2.8533058 ]\n",
            " [ 1.25736697 -2.89286672]\n",
            " [ 1.14917921 -0.99880582]\n",
            " [ 3.26406662 -2.82311517]\n",
            " [-3.22174178  0.79376713]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4361 - loss: 1.8390 - val_accuracy: 0.9919 - val_loss: 0.3685\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.4670 - val_accuracy: 0.9934 - val_loss: 0.0655\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.2424 - val_accuracy: 0.9926 - val_loss: 0.0316\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1499 - val_accuracy: 0.9926 - val_loss: 0.0251\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.1196 - val_accuracy: 0.9934 - val_loss: 0.0228\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.1034 - val_accuracy: 0.9934 - val_loss: 0.0196\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.0862 - val_accuracy: 0.9945 - val_loss: 0.0192\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0769 - val_accuracy: 0.9937 - val_loss: 0.0179\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0618 - val_accuracy: 0.9949 - val_loss: 0.0202\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0609 - val_accuracy: 0.9945 - val_loss: 0.0171\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0517 - val_accuracy: 0.9930 - val_loss: 0.0230\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0468 - val_accuracy: 0.9926 - val_loss: 0.0206\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0494 - val_accuracy: 0.9930 - val_loss: 0.0206\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0492 - val_accuracy: 0.9937 - val_loss: 0.0219\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0450 - val_accuracy: 0.9937 - val_loss: 0.0259\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0421 - val_accuracy: 0.9930 - val_loss: 0.0222\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0458 - val_accuracy: 0.9930 - val_loss: 0.0214\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0409 - val_accuracy: 0.9930 - val_loss: 0.0234\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0371 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0521 - val_accuracy: 0.9945 - val_loss: 0.0234\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0203\n",
            "Test Accuracy: 99.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make NN with last layer w/ 1 neuron\n",
        "\n",
        "Use same training data\n",
        "\n",
        "Save Train and Test as CSV\n",
        "\n",
        "\n",
        "\n",
        "Stage 1: Put the last layer as linear activation, map to 0-15\n",
        "\n",
        "Stage 2: See if we can use decision trees (what accuracy? how does it compare?)\n",
        "\n",
        "Stage 3: Increase size of dataset to 20k"
      ],
      "metadata": {
        "id": "jtXNL51UiiGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = np.array([[3, -3],[1, -3],[3, -1],[-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "predictions = model.predict(X_pred)\n",
        "print(f\"Predictions: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py1ldtIseMqg",
        "outputId": "dd7ec307-8dbc-48c7-ae1d-cbf56eb697bb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    }
  ]
}