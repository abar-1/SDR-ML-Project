{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/SDR-ML-Project/blob/main/QAMReceiverV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7L-Ly9L0tyM"
      },
      "source": [
        "Function to convert binary data to QAM16 constellations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WN2UEDeQ9Wry",
        "outputId": "3004f717-2ed5-4f0f-839c-47a1f1c8d77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\anees\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\anees\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr1JBlR5M6Us"
      },
      "source": [
        "16QAM Constellation Modulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_2GERHoIxaP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "Used https://dsplog.com/2008/06/01/binary-to-gray-code-for-16qam/ for mappings. When tested, the function works and\n",
        "the binary is correctly mapped to its correspondingcomplex number based on the constellation. To check, uncomment\n",
        "the last line in the cell which prints a test run of the function.\n",
        "\"\"\"\n",
        "\n",
        "def modulator(binary_data, M):\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # defining the real and imaginary PAM constellation for 16-QAM\n",
        "    alphaRe = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "    alphaIm = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "\n",
        "    # taking b0b1 for real\n",
        "    ipDecRe = np.array([int(''.join(map(str, b[:k//2])), 2) for b in binary_data])\n",
        "    ipGrayDecRe = ipDecRe ^ (ipDecRe >> 1)\n",
        "\n",
        "    # taking b2b3 for imaginary\n",
        "    ipDecIm = np.array([int(''.join(map(str, b[k//2:])), 2) for b in binary_data])\n",
        "    ipGrayDecIm = ipDecIm ^ (ipDecIm >> 1)\n",
        "\n",
        "    # mapping the Gray coded symbols into constellation\n",
        "    modRe = alphaRe[ipGrayDecRe]\n",
        "    modIm = alphaIm[ipGrayDecIm]\n",
        "\n",
        "    # complex constellation\n",
        "    mod = modRe + 1j * modIm\n",
        "\n",
        "    return mod\n",
        "\n",
        "def generate_qam_symbols(M=16, num_symbols=1000):\n",
        "    # 4 bits per symbol\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # Generate random binary data\n",
        "    random_bits = np.random.randint(0, 2, num_symbols * k)\n",
        "\n",
        "    # Reshape to match modulator input\n",
        "    binary_data = random_bits.reshape((-1, k))\n",
        "\n",
        "    # Modulate Binary Data\n",
        "    modulated_symbols = modulator(binary_data, M)\n",
        "\n",
        "    return modulated_symbols, binary_data\n",
        "#print(generate_qam_symbols(16,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVRNEKFJ0qCB"
      },
      "source": [
        "Adding noise to 16QAM signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "HNF_9MFqwuSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def add_awgn(qam_symbols, snr_db):\n",
        "    \"\"\"\n",
        "    Adds Additive White Gaussian Noise (AWGN) to QAM symbols.\n",
        "\n",
        "    Parameters:\n",
        "        qam_symbols (numpy array): The transmitted QAM symbols (complex numbers).\n",
        "        snr_db (float): Signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Noisy QAM symbols.\n",
        "    \"\"\"\n",
        "    # Calculate signal power\n",
        "    signal_power = np.mean(np.abs(qam_symbols) ** 2)\n",
        "\n",
        "    # Compute noise power based on SNR (convert dB to linear scale)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "\n",
        "    # Generate AWGN noise\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*qam_symbols.shape) + 1j * np.random.randn(*qam_symbols.shape))\n",
        "\n",
        "    # Add noise to the symbols\n",
        "    noisy_qam_symbols = qam_symbols + noise\n",
        "    return noisy_qam_symbols\n",
        "\n",
        "\n",
        "# Generate 16QAM symbols\n",
        "M = 16\n",
        "num_symbols = 1000\n",
        "qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "\n",
        "#Signal to noise ratio in dB\n",
        "#High signal to noise ratio is good, low is bad\n",
        "snr_db = 15\n",
        "\n",
        "\n",
        "# Add noise to QAM symbols\n",
        "noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "\n",
        "df = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.drop(['index'],axis=1,inplace=True)\n",
        "\n",
        "#Getting data of different noise levels (data augmentation to prevent overfitting)\n",
        "for i in range(15, 55, 5):\n",
        "  M = 16\n",
        "  num_symbols = 2000\n",
        "  qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "  snr_db = i\n",
        "  noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "  df1 = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "  df1.reset_index(inplace=True)\n",
        "  df1.drop(['index'],axis=1,inplace=True)\n",
        "  df = pd.concat([df, df1])\n",
        "\n",
        "  #Plot Constellations (Before and After Noise)\n",
        "  # plt.figure(figsize=(10,5))\n",
        "  # plt.subplot(1,2,2)\n",
        "  # plt.scatter(noisy_qam.real, noisy_qam.imag, alpha=0.5, label=\"Noisy\")\n",
        "  # plt.title(f\"Signal to Noise Ratio = {snr_db} dB)\")\n",
        "  # plt.xlabel(\"In-phase (I)\")\n",
        "  # plt.ylabel(\"Quadrature (Q)\")\n",
        "  # plt.grid()\n",
        "\n",
        "  #plt.show()\n",
        "df = df.rename(columns={'features': 'binary','target':'complex'})\n",
        "#To save as CSV\n",
        "df.to_csv('dataWithNoise.csv', index = False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKPQnpx0kaq"
      },
      "source": [
        "Build Neural Network\n",
        "\n",
        "X = Complex\n",
        "\n",
        "y = Binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M_a12Dw20oPB",
        "outputId": "7fd07647-29a6-4033-969b-89e97d5b993c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0778 - mae: 0.0907 - val_loss: 0.0281 - val_mae: 0.0583\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0201 - mae: 0.0334 - val_loss: 0.0054 - val_mae: 0.0090\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0096 - mae: 0.0191 - val_loss: 0.0029 - val_mae: 0.0031\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0138 - val_loss: 0.0022 - val_mae: 0.0014\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0113 - val_loss: 0.0018 - val_mae: 7.4376e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0109 - val_loss: 0.0019 - val_mae: 7.5059e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0090 - val_loss: 0.0017 - val_mae: 6.3484e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0084 - val_loss: 0.0017 - val_mae: 2.6971e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0044 - mae: 0.0080 - val_loss: 0.0017 - val_mae: 1.8043e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0073 - val_loss: 0.0017 - val_mae: 2.4682e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0072 - val_loss: 0.0017 - val_mae: 3.6839e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0069 - val_loss: 0.0017 - val_mae: 3.5057e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 2.2541e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0059 - val_loss: 0.0016 - val_mae: 1.1225e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0066 - val_loss: 0.0017 - val_mae: 1.3499e-04\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0046 - mae: 0.0097 - val_loss: 0.0016 - val_mae: 5.5647e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0045 - mae: 0.0084 - val_loss: 0.0016 - val_mae: 2.6707e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0080 - val_loss: 0.0015 - val_mae: 3.2137e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0075 - val_loss: 0.0017 - val_mae: 1.9331e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0078 - val_loss: 0.0017 - val_mae: 1.8475e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0068 - val_loss: 0.0017 - val_mae: 1.7781e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0070 - val_loss: 0.0017 - val_mae: 1.2674e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0066 - val_loss: 0.0017 - val_mae: 1.2506e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0063 - val_loss: 0.0017 - val_mae: 1.0056e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0059 - val_loss: 0.0017 - val_mae: 6.1120e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0035 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 8.0904e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0048 - mae: 0.0091 - val_loss: 0.0016 - val_mae: 3.4297e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0082 - val_loss: 0.0015 - val_mae: 3.1303e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0043 - mae: 0.0076 - val_loss: 0.0016 - val_mae: 2.5363e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0046 - mae: 0.0078 - val_loss: 0.0017 - val_mae: 1.8063e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0044 - mae: 0.0071 - val_loss: 0.0016 - val_mae: 1.4760e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0072 - val_loss: 0.0017 - val_mae: 9.7500e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0065 - val_loss: 0.0016 - val_mae: 1.8102e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0064 - val_loss: 0.0017 - val_mae: 9.5390e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0044 - mae: 0.0066 - val_loss: 0.0017 - val_mae: 9.7124e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0063 - val_loss: 0.0017 - val_mae: 7.6984e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0055 - val_loss: 0.0017 - val_mae: 6.0188e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0080 - val_loss: 0.0016 - val_mae: 1.8307e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0070 - val_loss: 0.0016 - val_mae: 1.7603e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0070 - val_loss: 0.0017 - val_mae: 1.8783e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0067 - val_loss: 0.0016 - val_mae: 1.2160e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0066 - val_loss: 0.0016 - val_mae: 9.5836e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038 - mae: 0.0060 - val_loss: 0.0017 - val_mae: 5.5134e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0057 - val_loss: 0.0017 - val_mae: 6.7207e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0061 - val_loss: 0.0017 - val_mae: 7.3028e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 4.8124e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0053 - val_loss: 0.0017 - val_mae: 1.0004e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 7.7599e-05\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0076 - val_loss: 0.0015 - val_mae: 2.5406e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0072 - val_loss: 0.0016 - val_mae: 1.5775e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0073 - val_loss: 0.0015 - val_mae: 1.5694e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0063 - val_loss: 0.0017 - val_mae: 8.4187e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0063 - val_loss: 0.0017 - val_mae: 1.0249e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0045 - mae: 0.0066 - val_loss: 0.0017 - val_mae: 9.0074e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 5.6966e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0037 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 6.7139e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0060 - val_loss: 0.0016 - val_mae: 1.0705e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 6.0704e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0058 - val_loss: 0.0018 - val_mae: 8.3479e-05\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1da33951c312>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2245\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \"\"\"\n\u001b[0;32m-> 2247\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   2248\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import mean_squared_error, precision_score,recall_score\n",
        "\n",
        "#Target variable (binary data)\n",
        "y = df['binary'].values\n",
        "# Convert each element of y to a NumPy array\n",
        "y = np.array([np.array(yi) for yi in y])\n",
        "#Reshape to 4 bits/symbol (-1 means numpy will figure out how many rows are needed)\n",
        "y = y.reshape(-1, 4)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Manually convert 4-bit binary to integer (0-15)\n",
        "y = np.array([int(\"\".join(str(bit) for bit in row), 2) for row in y])\n",
        "\n",
        "# One-hot encoding for 16 classes\n",
        "y = to_categorical(y, num_classes=16)\n",
        "\n",
        "\n",
        "# Features (complex data)\n",
        "X = df['complex'].values\n",
        "X = np.array([np.array(xi) for xi in X])\n",
        "\n",
        "# Reshape to (n_samples, 2) for real and imaginary parts\n",
        "X = [[x.real, x.imag] for x in X]\n",
        "X = np.array(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(2,),\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu',\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # 16 neurons for 16 different possibilities (0000 - 1111)\n",
        "    Dense(16, activation='softmax')\n",
        "])\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "y = np.round(y)\n",
        "accuracies = [] #list to store the accuracy per fold\n",
        "for train_index, test_index in kfold.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train_norm = y_train / 15\n",
        "    y_test_norm = y_test / 15\n",
        "\n",
        "    earlyStopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.001)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1,\n",
        "                        callbacks=[earlyStopping])\n",
        "    val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    cv_scores.append(val_acc)\n",
        "\n",
        "\n",
        "# print(f\"Cross-validation scores: {cv_scores}\")\n",
        "# print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "accuracy = 100 - (mse / np.mean(y_test)) * 100\n",
        "\n",
        "# Convert probabilities to class predictions\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "precision = precision_score(y_test_classes, y_pred_classes, average='weighted') # changed average to weighted\n",
        "recall = recall_score(y_test_classes, y_pred_classes, average='weighted')  # changed average to weighted\n",
        "\n",
        "print(\"MSE:\", mse)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "id": "LDu5gj7-swdL",
        "outputId": "1e194db2-198c-424d-c29e-5759f2dd52fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "MSE: 0.0005557986034798999\n",
            "Accuracy: 99.11072223443216\n",
            "Precision: 0.9944384451775025\n",
            "Recall: 0.9944117647058823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Py1ldtIseMqg",
        "outputId": "ea42acf1-0015-44c8-e161-62ed5a94ffd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Complex Input:  [[ 2.5 -3. ]\n",
            " [ 1.  -3. ]\n",
            " [ 3.  -1. ]\n",
            " [-1.   3. ]]\n",
            "Model Predictions:  ['1000', '1100', '1001', '1100']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [((-3, -3), 0000), ((-3,-1), 0001), ((-3, 1), 0011), ((-3, 3), 0010), ((-1, -3), 0100), ((-1, -1), 0101), ((-1, 1), 0111), ((-1, 3), 0110), ((1, -3), 1100), ((1, -1), 1101), ((1, 1), 1111), ((1, 3), 1110), ((3, -3), 1000), ((3, -1), 1001), ((3, 1, 1011), ((3, 3), 1010)]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a729c359-4364-4835-a6d4-3d70bb12714a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>(-3, -3)</th>\n",
              "      <th>(-3,-1)</th>\n",
              "      <th>(-3, 1)</th>\n",
              "      <th>(-3, 3)</th>\n",
              "      <th>(-1, -3)</th>\n",
              "      <th>(-1, -1)</th>\n",
              "      <th>(-1, 1)</th>\n",
              "      <th>(-1, 3)</th>\n",
              "      <th>(1, -3)</th>\n",
              "      <th>(1, -1)</th>\n",
              "      <th>(1, 1)</th>\n",
              "      <th>(1, 3)</th>\n",
              "      <th>(3, -3)</th>\n",
              "      <th>(3, -1)</th>\n",
              "      <th>(3, 1</th>\n",
              "      <th>(3, 3)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>0000</th>\n",
              "      <th>0001</th>\n",
              "      <th>0011</th>\n",
              "      <th>0010</th>\n",
              "      <th>0100</th>\n",
              "      <th>0101</th>\n",
              "      <th>0111</th>\n",
              "      <th>0110</th>\n",
              "      <th>1100</th>\n",
              "      <th>1101</th>\n",
              "      <th>1111</th>\n",
              "      <th>1110</th>\n",
              "      <th>1000</th>\n",
              "      <th>1001</th>\n",
              "      <th>1011</th>\n",
              "      <th>1010</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a729c359-4364-4835-a6d4-3d70bb12714a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a729c359-4364-4835-a6d4-3d70bb12714a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a729c359-4364-4835-a6d4-3d70bb12714a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_3142ca2f-ebef-47c5-ad9a-2e0a7a33a9fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compare')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3142ca2f-ebef-47c5-ad9a-2e0a7a33a9fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compare');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_pred = np.array([[2.5, -3], [1, -3], [3, -1], [-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "# Assuming model.predict(X_pred) gives some output\n",
        "temp = model.predict(X_pred)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# Find the index of the max value in each prediction\n",
        "for x in range(len(temp)):\n",
        "    max_val = max(temp[x])\n",
        "    predictions.append(np.where(temp[x] == max_val)[0][0])\n",
        "print(\"Complex Input: \", X_pred)\n",
        "\n",
        "\n",
        "binarylist = []\n",
        "for num in predictions:\n",
        "    binary = \"\"\n",
        "    if num == 0:\n",
        "        binary = \"0000\"\n",
        "    else:\n",
        "        while num > 0:\n",
        "            binary = str(num % 2) + binary\n",
        "            num //= 2\n",
        "    if(len(binary)) < 4:\n",
        "        binary += \"0\"\n",
        "    binarylist.append(binary)\n",
        "print(\"Model Predictions: \", binarylist)\n",
        "comlex = [\"(-3, -3)\",\"(-3,-1)\",\"(-3, 1)\",\"(-3, 3)\",\"(-1, -3)\",\"(-1, -1)\",\"(-1, 1)\",\"(-1, 3)\",\"(1, -3)\",\"(1, -1)\",\"(1, 1)\",\"(1, 3)\",\"(3, -3)\",\"(3, -1)\",\"(3, 1\",\"(3, 3)\"]\n",
        "bin = [\"0000\",\"0001\",\"0011\",\"0010\",\"0100\",\"0101\",\"0111\",\"0110\",\"1100\",\"1101\",\"1111\",\"1110\",\"1000\",\"1001\",\"1011\",\"1010\"]\n",
        "\n",
        "#Making df to help test predictions\n",
        "compare = pd.DataFrame(columns=[comlex, bin])\n",
        "compare\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}