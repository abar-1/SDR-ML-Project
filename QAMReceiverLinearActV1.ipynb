{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaPMfPzbqDk5lRfVZdr5MW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abar-1/SDR-ML-Project/blob/linearActivation/QAMReceiverLinearActV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert binary data to QAM16 constellations"
      ],
      "metadata": {
        "id": "D7L-Ly9L0tyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN2UEDeQ9Wry",
        "outputId": "3004f717-2ed5-4f0f-839c-47a1f1c8d77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16QAM Constellation Modulator"
      ],
      "metadata": {
        "id": "wr1JBlR5M6Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "Used https://dsplog.com/2008/06/01/binary-to-gray-code-for-16qam/ for mappings. When tested, the function works and\n",
        "the binary is correctly mapped to its correspondingcomplex number based on the constellation. To check, uncomment\n",
        "the last line in the cell which prints a test run of the function.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def modulator(binary_data, M):\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # defining the real and imaginary PAM constellation for 16-QAM\n",
        "    alphaRe = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "    alphaIm = np.arange(-(2*np.sqrt(M)/2-1), (2*np.sqrt(M)/2), 2)\n",
        "\n",
        "    # taking b0b1 for real\n",
        "    ipDecRe = np.array([int(''.join(map(str, b[:k//2])), 2) for b in binary_data])\n",
        "    ipGrayDecRe = ipDecRe ^ (ipDecRe >> 1)\n",
        "\n",
        "    # taking b2b3 for imaginary\n",
        "    ipDecIm = np.array([int(''.join(map(str, b[k//2:])), 2) for b in binary_data])\n",
        "    ipGrayDecIm = ipDecIm ^ (ipDecIm >> 1)\n",
        "\n",
        "    # mapping the Gray coded symbols into constellation\n",
        "    modRe = alphaRe[ipGrayDecRe]\n",
        "    modIm = alphaIm[ipGrayDecIm]\n",
        "\n",
        "    # complex constellation\n",
        "    mod = modRe + 1j * modIm\n",
        "\n",
        "    return mod\n",
        "\n",
        "def generate_qam_symbols(M=16, num_symbols=1000):\n",
        "    # 4 bits per symbol\n",
        "    k = int(np.log2(M))\n",
        "\n",
        "    # Generate random binary data\n",
        "    random_bits = np.random.randint(0, 2, num_symbols * k)\n",
        "\n",
        "    # Reshape to match modulator input\n",
        "    binary_data = random_bits.reshape((-1, k))\n",
        "\n",
        "    # Modulate Binary Data\n",
        "    modulated_symbols = modulator(binary_data, M)\n",
        "\n",
        "    return modulated_symbols, binary_data\n",
        "#print(generate_qam_symbols(16,5))"
      ],
      "metadata": {
        "id": "q_2GERHoIxaP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding noise to 16QAM signals"
      ],
      "metadata": {
        "id": "mVRNEKFJ0qCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def add_awgn(qam_symbols, snr_db):\n",
        "    \"\"\"\n",
        "    Adds Additive White Gaussian Noise (AWGN) to QAM symbols.\n",
        "\n",
        "    Parameters:\n",
        "        qam_symbols (numpy array): The transmitted QAM symbols (complex numbers).\n",
        "        snr_db (float): Signal-to-noise ratio in dB.\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Noisy QAM symbols.\n",
        "    \"\"\"\n",
        "    # Calculate signal power\n",
        "    signal_power = np.mean(np.abs(qam_symbols) ** 2)\n",
        "\n",
        "    # Compute noise power based on SNR (convert dB to linear scale)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "\n",
        "    # Generate AWGN noise\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*qam_symbols.shape) + 1j * np.random.randn(*qam_symbols.shape))\n",
        "\n",
        "    # Add noise to the symbols\n",
        "    noisy_qam_symbols = qam_symbols + noise\n",
        "    return noisy_qam_symbols\n",
        "\n",
        "\n",
        "# Generate 16QAM symbols\n",
        "M = 16\n",
        "num_symbols = 1000\n",
        "qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "\n",
        "#Signal to noise ratio in dB\n",
        "#High signal to noise ratio is good, low is bad\n",
        "snr_db = 15\n",
        "\n",
        "\n",
        "# Add noise to QAM symbols\n",
        "noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "\n",
        "df = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "df.drop(['index'],axis=1,inplace=True)\n",
        "\n",
        "#Getting data of different noise levels (data augmentation to prevent overfitting)\n",
        "for i in range(15, 55, 5):\n",
        "  M = 16\n",
        "  num_symbols = 2000\n",
        "  qam_symbols, original_binary = generate_qam_symbols(M, num_symbols)\n",
        "  snr_db = i\n",
        "  noisy_qam = add_awgn(qam_symbols, snr_db)\n",
        "  df1 = pd.DataFrame({'features':original_binary.tolist(), 'target':noisy_qam.tolist()})\n",
        "  df1.reset_index(inplace=True)\n",
        "  df1.drop(['index'],axis=1,inplace=True)\n",
        "  df = pd.concat([df, df1])\n",
        "\n",
        "  #Plot Constellations (Before and After Noise)\n",
        "  # plt.figure(figsize=(10,5))\n",
        "  # plt.subplot(1,2,2)\n",
        "  # plt.scatter(noisy_qam.real, noisy_qam.imag, alpha=0.5, label=\"Noisy\")\n",
        "  # plt.title(f\"Signal to Noise Ratio = {snr_db} dB)\")\n",
        "  # plt.xlabel(\"In-phase (I)\")\n",
        "  # plt.ylabel(\"Quadrature (Q)\")\n",
        "  # plt.grid()\n",
        "\n",
        "  #plt.show()\n",
        "df = df.rename(columns={'features': 'binary','target':'complex'})\n",
        "#To save as CSV\n",
        "df.to_csv('dataWithNoise.csv', index = False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HNF_9MFqwuSN",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Neural Network\n",
        "\n",
        "X = Complex\n",
        "\n",
        "y = Binary converted to Decimal"
      ],
      "metadata": {
        "id": "omKPQnpx0kaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers\n",
        "#from sklearn.model_selection import cross_val_score #Remove this line\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('dataWithNoise.csv')\n",
        "\n",
        "# Keep target variable as integers (0-15)\n",
        "y = df['binary'].values\n",
        "y = [eval(yi) for yi in y] #convert string to list of ints\n",
        "y = np.array(y)\n",
        "y = y.reshape(-1, 4)\n",
        "\n",
        "y = np.array([int(\"\".join(str(bit) for bit in row), 2) for row in y])\n",
        "\n",
        "\n",
        "# Features (unchanged)\n",
        "X = df['complex'].values\n",
        "X = [eval(xi) for xi in X] #convert string to list of ints\n",
        "X = np.array([[x.real, x.imag] for x in X])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train_norm = y_train / 15.0\n",
        "y_test_norm = y_test / 15.0\n",
        "# Build the regression model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(2,),\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu',\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='linear')  # Regression output\n",
        "])\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "y = np.round(y)\n",
        "accuracies = [] #list to store the accuracy per fold\n",
        "for train_index, test_index in kfold.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    y_train_norm = y_train / 15\n",
        "    y_test_norm = y_test / 15\n",
        "\n",
        "    earlyStopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.001)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        validation_split=0.2,\n",
        "                        verbose=1,\n",
        "                        callbacks=[earlyStopping])\n",
        "    val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    cv_scores.append(val_acc)\n",
        "\n",
        "\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
        "\n",
        "\n",
        "\n",
        "#Predict on the given values\n",
        "X_pred = np.array([[3, -3],[1, -3],[3, -1],[-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "predictions = model.predict(X_pred)\n",
        "rounded_predictions = np.round(predictions).astype(int)\n",
        "print(f\"Predictions: {rounded_predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a12Dw20oPB",
        "outputId": "ffd7ef07-f667-4b78-ead8-85675d5a9213"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 55.0219 - mae: 6.8108 - val_loss: 13.7088 - val_mae: 3.5183\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.2649 - mae: 2.4672 - val_loss: 0.3203 - val_mae: 0.4403\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0388 - mae: 1.5736 - val_loss: 0.2458 - val_mae: 0.3416\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2696 - mae: 1.4012 - val_loss: 0.2250 - val_mae: 0.3333\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1783 - mae: 1.3783 - val_loss: 0.1939 - val_mae: 0.3096\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7367 - mae: 1.2795 - val_loss: 0.1799 - val_mae: 0.3078\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9900 - mae: 1.3414 - val_loss: 0.1345 - val_mae: 0.2465\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5672 - mae: 1.2353 - val_loss: 0.1070 - val_mae: 0.1993\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5651 - mae: 1.2426 - val_loss: 0.1513 - val_mae: 0.2772\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5255 - mae: 1.2203 - val_loss: 0.0956 - val_mae: 0.1786\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4823 - mae: 1.2060 - val_loss: 0.1626 - val_mae: 0.2878\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4418 - mae: 1.1964 - val_loss: 0.1359 - val_mae: 0.2229\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4424 - mae: 1.2086 - val_loss: 0.1337 - val_mae: 0.2542\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.6196 - mae: 1.2418 - val_loss: 0.1261 - val_mae: 0.2287\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2.3096 - mae: 1.1694 - val_loss: 0.1310 - val_mae: 0.2565\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4890 - mae: 1.2157 - val_loss: 0.1319 - val_mae: 0.2347\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3515 - mae: 1.1827 - val_loss: 0.0877 - val_mae: 0.1658\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3298 - mae: 1.1645 - val_loss: 0.0873 - val_mae: 0.1734\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1777 - mae: 1.1379 - val_loss: 0.1008 - val_mae: 0.2001\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3168 - mae: 1.1715 - val_loss: 0.0791 - val_mae: 0.1572\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2.2943 - mae: 1.1712 - val_loss: 0.1425 - val_mae: 0.2631\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2608 - mae: 1.1602 - val_loss: 0.1039 - val_mae: 0.1966\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2709 - mae: 1.1663 - val_loss: 0.0808 - val_mae: 0.1826\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2010 - mae: 1.1413 - val_loss: 0.1318 - val_mae: 0.2510\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.0126 - mae: 1.0868 - val_loss: 0.1012 - val_mae: 0.2130\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1590 - mae: 1.1140 - val_loss: 0.0780 - val_mae: 0.1539\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0458 - mae: 1.1014 - val_loss: 0.0900 - val_mae: 0.1910\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0990 - mae: 1.1135 - val_loss: 0.0710 - val_mae: 0.1629\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9388 - mae: 1.0710 - val_loss: 0.1281 - val_mae: 0.2361\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1584 - mae: 1.1336 - val_loss: 0.0620 - val_mae: 0.1419\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9866 - mae: 1.0781 - val_loss: 0.0948 - val_mae: 0.1821\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9953 - mae: 1.0845 - val_loss: 0.0679 - val_mae: 0.1607\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.9079 - mae: 1.0688 - val_loss: 0.1101 - val_mae: 0.2389\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9341 - mae: 1.0703 - val_loss: 0.0940 - val_mae: 0.2045\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9269 - mae: 1.0597 - val_loss: 0.1332 - val_mae: 0.2408\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9654 - mae: 1.0807 - val_loss: 0.1422 - val_mae: 0.2872\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9708 - mae: 1.0792 - val_loss: 0.1119 - val_mae: 0.2356\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8786 - mae: 1.0544 - val_loss: 0.1425 - val_mae: 0.2790\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9592 - mae: 1.0828 - val_loss: 0.0904 - val_mae: 0.2084\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9950 - mae: 1.0749 - val_loss: 0.1767 - val_mae: 0.3153\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.8505 - mae: 1.0428 - val_loss: 0.0783 - val_mae: 0.1805\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1258 - mae: 1.1247 - val_loss: 0.0732 - val_mae: 0.1690\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9699 - mae: 1.0653 - val_loss: 0.0973 - val_mae: 0.1749\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9821 - mae: 1.0745 - val_loss: 0.0747 - val_mae: 0.1779\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0858 - mae: 1.1208 - val_loss: 0.1350 - val_mae: 0.2518\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9335 - mae: 1.0816 - val_loss: 0.1129 - val_mae: 0.2380\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9318 - mae: 1.0611 - val_loss: 0.0921 - val_mae: 0.2005\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9695 - mae: 1.0805 - val_loss: 0.0980 - val_mae: 0.2043\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9940 - mae: 1.0910 - val_loss: 0.0648 - val_mae: 0.1506\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.9535 - mae: 1.0748 - val_loss: 0.0945 - val_mae: 0.1991\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9022 - mae: 1.0612 - val_loss: 0.0961 - val_mae: 0.2094\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7575 - mae: 1.0174 - val_loss: 0.0680 - val_mae: 0.1695\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9239 - mae: 1.0624 - val_loss: 0.1910 - val_mae: 0.3475\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8473 - mae: 1.0423 - val_loss: 0.0752 - val_mae: 0.1729\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9680 - mae: 1.0882 - val_loss: 0.0743 - val_mae: 0.1578\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9169 - mae: 1.0675 - val_loss: 0.1049 - val_mae: 0.2110\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0322 - mae: 1.0953 - val_loss: 0.0705 - val_mae: 0.1765\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7976 - mae: 1.0300 - val_loss: 0.0491 - val_mae: 0.1158\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8879 - mae: 1.0487 - val_loss: 0.1153 - val_mae: 0.2270\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8170 - mae: 1.0423 - val_loss: 0.0917 - val_mae: 0.2099\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 1.7784 - mae: 1.0242 - val_loss: 0.0666 - val_mae: 0.1543\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7340 - mae: 1.0162 - val_loss: 0.0715 - val_mae: 0.1500\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7376 - mae: 1.0220 - val_loss: 0.0976 - val_mae: 0.2119\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8945 - mae: 1.0459 - val_loss: 0.0930 - val_mae: 0.1954\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7299 - mae: 1.0132 - val_loss: 0.1131 - val_mae: 0.2150\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7931 - mae: 1.0274 - val_loss: 0.0513 - val_mae: 0.1218\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8127 - mae: 1.0379 - val_loss: 0.1132 - val_mae: 0.2177\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6496 - mae: 0.9881 - val_loss: 0.0672 - val_mae: 0.1546\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.8313 - mae: 1.0520 - val_loss: 0.0746 - val_mae: 0.1746\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7457 - mae: 1.0147 - val_loss: 0.0638 - val_mae: 0.1537\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7972 - mae: 1.0367 - val_loss: 0.0687 - val_mae: 0.1554\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8033 - mae: 1.0274 - val_loss: 0.0905 - val_mae: 0.1888\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8420 - mae: 1.0421 - val_loss: 0.0579 - val_mae: 0.1288\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8002 - mae: 1.0396 - val_loss: 0.0919 - val_mae: 0.2056\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8223 - mae: 1.0414 - val_loss: 0.0651 - val_mae: 0.1561\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8838 - mae: 1.0428 - val_loss: 0.0491 - val_mae: 0.1194\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.7903 - mae: 1.0435 - val_loss: 0.0859 - val_mae: 0.1986\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7713 - mae: 1.0238 - val_loss: 0.0717 - val_mae: 0.1648\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7720 - mae: 1.0239 - val_loss: 0.0740 - val_mae: 0.1547\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8416 - mae: 1.0492 - val_loss: 0.0954 - val_mae: 0.2002\n",
            "Epoch 1/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.7528 - mae: 1.0245 - val_loss: 0.1346 - val_mae: 0.2700\n",
            "Epoch 2/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8577 - mae: 1.0593 - val_loss: 0.0667 - val_mae: 0.1577\n",
            "Epoch 3/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9902 - mae: 1.0956 - val_loss: 0.0842 - val_mae: 0.1810\n",
            "Epoch 4/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6539 - mae: 0.9869 - val_loss: 0.0522 - val_mae: 0.1360\n",
            "Epoch 5/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.8886 - mae: 1.0535 - val_loss: 0.1157 - val_mae: 0.2387\n",
            "Epoch 6/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6696 - mae: 0.9967 - val_loss: 0.0562 - val_mae: 0.1345\n",
            "Epoch 7/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9015 - mae: 1.0589 - val_loss: 0.1433 - val_mae: 0.2178\n",
            "Epoch 8/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8853 - mae: 1.0537 - val_loss: 0.0688 - val_mae: 0.1538\n",
            "Epoch 9/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6828 - mae: 0.9979 - val_loss: 0.0630 - val_mae: 0.1516\n",
            "Epoch 10/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8194 - mae: 1.0418 - val_loss: 0.0566 - val_mae: 0.1262\n",
            "Epoch 11/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6464 - mae: 0.9880 - val_loss: 0.0504 - val_mae: 0.1130\n",
            "Epoch 12/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7321 - mae: 1.0061 - val_loss: 0.0622 - val_mae: 0.1375\n",
            "Epoch 13/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6540 - mae: 0.9895 - val_loss: 0.0686 - val_mae: 0.1737\n",
            "Epoch 14/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7823 - mae: 1.0079 - val_loss: 0.0853 - val_mae: 0.1966\n",
            "Epoch 15/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6974 - mae: 1.0075 - val_loss: 0.0713 - val_mae: 0.1501\n",
            "Epoch 16/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.8218 - mae: 1.0449 - val_loss: 0.0748 - val_mae: 0.1692\n",
            "Epoch 17/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6983 - mae: 1.0009 - val_loss: 0.0529 - val_mae: 0.1206\n",
            "Epoch 18/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6861 - mae: 1.0012 - val_loss: 0.0728 - val_mae: 0.1525\n",
            "Epoch 19/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7551 - mae: 1.0248 - val_loss: 0.0783 - val_mae: 0.1616\n",
            "Epoch 20/20\n",
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6343 - mae: 0.9843 - val_loss: 0.0653 - val_mae: 0.1487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 110 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7885f9c0bce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.2552356719970703, 0.2215694636106491, 0.18147745728492737, 0.1756616085767746, 0.16920097172260284]\n",
            "Mean CV Accuracy: 0.2006 (+/- 0.0329)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Predictions: [[ 8]\n",
            " [12]\n",
            " [ 9]\n",
            " [ 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = np.array([[3, -3],[1, -3],[3, -1],[-1, 3]])  # Convert X_pred to a NumPy array\n",
        "\n",
        "predictions = model.predict(X_pred)\n",
        "print(f\"Predictions: {predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py1ldtIseMqg",
        "outputId": "dd7ec307-8dbc-48c7-ae1d-cbf56eb697bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ]
        }
      ]
    }
  ]
}